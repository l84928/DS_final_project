{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, AutoTokenizer, AutoModel, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\seaborn\\rcmod.py:82: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(mpl.__version__) >= \"3.0\":\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\setuptools\\_distutils\\version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ying\n",
      "[nltk_data]     Jhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ying\n",
      "[nltk_data]     Jhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Ying\n",
      "[nltk_data]     Jhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Ying\n",
      "[nltk_data]     Jhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ying Jhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\gensim\\matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "logical_devices = tf.config.list_logical_devices(\"GPU\")\n",
    "from tf_geometric.utils import tf_utils\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow import keras\n",
    "import tf_geometric as tfg\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, SimpleRNN, LSTM\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense, SimpleRNN, LSTM, Dropout\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report , accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "from sklearn.linear_model import LogisticRegressionCV \n",
    "from sklearn import preprocessing\n",
    "\n",
    "random.seed(200)\n",
    "np.random.seed(200)\n",
    "tf.random.set_seed(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_url</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.359351e+18</td>\n",
       "      <td>http://twitter.com/user/status/135935094335617...</td>\n",
       "      <td>India's gift of 100,000 COVID-19 vaccines arri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.350166e+18</td>\n",
       "      <td>http://twitter.com/user/status/135016568806166...</td>\n",
       "      <td>Here’s what I’m doing while I wait my turn for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.369750e+18</td>\n",
       "      <td>http://twitter.com/user/status/136974953915491...</td>\n",
       "      <td>This afternoon, I’m hosting an event with the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.350165e+18</td>\n",
       "      <td>http://twitter.com/user/status/135016499568693...</td>\n",
       "      <td>Help shops like mine stay open. Mask up, avoid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.370008e+18</td>\n",
       "      <td>http://twitter.com/user/status/137000807648978...</td>\n",
       "      <td>As part of the ongoing nationwide vaccination ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.242137e+18</td>\n",
       "      <td>http://twitter.com/user/status/124213681646938...</td>\n",
       "      <td>my flintstones gummies from 15 years ago fight...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.236095e+18</td>\n",
       "      <td>http://twitter.com/user/status/123609539969108...</td>\n",
       "      <td>#COVIDã¼19 Something we all need to be aware ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3627</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.370092e+18</td>\n",
       "      <td>http://twitter.com/user/status/137009191790463...</td>\n",
       "      <td>Some of the most vulnerable people in Alabama,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3628</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.369492e+18</td>\n",
       "      <td>http://twitter.com/user/status/136949228214833...</td>\n",
       "      <td>It would be great if our first responders coul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>COVID-19</td>\n",
       "      <td>1.370408e+18</td>\n",
       "      <td>http://twitter.com/user/status/137040826627930...</td>\n",
       "      <td>As states and the federal government roll out ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3630 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic      tweet_id  \\\n",
       "0     COVID-19  1.359351e+18   \n",
       "1     COVID-19  1.350166e+18   \n",
       "2     COVID-19  1.369750e+18   \n",
       "3     COVID-19  1.350165e+18   \n",
       "4     COVID-19  1.370008e+18   \n",
       "...        ...           ...   \n",
       "3625  COVID-19  1.242137e+18   \n",
       "3626  COVID-19  1.236095e+18   \n",
       "3627  COVID-19  1.370092e+18   \n",
       "3628  COVID-19  1.369492e+18   \n",
       "3629  COVID-19  1.370408e+18   \n",
       "\n",
       "                                              tweet_url  \\\n",
       "0     http://twitter.com/user/status/135935094335617...   \n",
       "1     http://twitter.com/user/status/135016568806166...   \n",
       "2     http://twitter.com/user/status/136974953915491...   \n",
       "3     http://twitter.com/user/status/135016499568693...   \n",
       "4     http://twitter.com/user/status/137000807648978...   \n",
       "...                                                 ...   \n",
       "3625  http://twitter.com/user/status/124213681646938...   \n",
       "3626  http://twitter.com/user/status/123609539969108...   \n",
       "3627  http://twitter.com/user/status/137009191790463...   \n",
       "3628  http://twitter.com/user/status/136949228214833...   \n",
       "3629  http://twitter.com/user/status/137040826627930...   \n",
       "\n",
       "                                             tweet_text  class_label  \n",
       "0     India's gift of 100,000 COVID-19 vaccines arri...            0  \n",
       "1     Here’s what I’m doing while I wait my turn for...            0  \n",
       "2     This afternoon, I’m hosting an event with the ...            0  \n",
       "3     Help shops like mine stay open. Mask up, avoid...            0  \n",
       "4     As part of the ongoing nationwide vaccination ...            0  \n",
       "...                                                 ...          ...  \n",
       "3625  my flintstones gummies from 15 years ago fight...            0  \n",
       "3626  #COVIDã¼19 Something we all need to be aware ...            1  \n",
       "3627  Some of the most vulnerable people in Alabama,...            0  \n",
       "3628  It would be great if our first responders coul...            0  \n",
       "3629  As states and the federal government roll out ...            0  \n",
       "\n",
       "[3630 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('CT22_english_1C_harmful_train+val.txt',sep='\\t')\n",
    "test=pd.read_csv('CT22_english_1C_harmful_dev_test.tsv',sep='\\t')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>India's gift of 100,000 COVID-19 vaccines arri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Here?s what I?m doing while I wait my turn f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This afternoon, I?m hosting an event with the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Help shops like mine stay open. Mask up, avoid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>As part of the ongoing nationwide vaccination ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>2902</td>\n",
       "      <td>@realDonaldTrump Donald scoop scrub his actuat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6507</th>\n",
       "      <td>2903</td>\n",
       "      <td>New York AG monish televangelist #JimBakker To...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6508</th>\n",
       "      <td>2904</td>\n",
       "      <td>Zika, Ebola, Lyme disease, German measles, spa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6509</th>\n",
       "      <td>2905</td>\n",
       "      <td>The President wonÃ¢??t let uracil witness this...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6510</th>\n",
       "      <td>2906</td>\n",
       "      <td>#COVIDÃ£?Â¼19 Something we all take to be cogn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         tweet_text  \\\n",
       "0              0  India's gift of 100,000 COVID-19 vaccines arri...   \n",
       "1              1  Here?s what I?m doing while I wait my turn f...   \n",
       "2              2  This afternoon, I?m hosting an event with the...   \n",
       "3              3  Help shops like mine stay open. Mask up, avoid...   \n",
       "4              4  As part of the ongoing nationwide vaccination ...   \n",
       "...          ...                                                ...   \n",
       "6506        2902  @realDonaldTrump Donald scoop scrub his actuat...   \n",
       "6507        2903  New York AG monish televangelist #JimBakker To...   \n",
       "6508        2904  Zika, Ebola, Lyme disease, German measles, spa...   \n",
       "6509        2905  The President wonÃ¢??t let uracil witness this...   \n",
       "6510        2906  #COVIDÃ£?Â¼19 Something we all take to be cogn...   \n",
       "\n",
       "      class_label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "6506            1  \n",
       "6507            1  \n",
       "6508            1  \n",
       "6509            1  \n",
       "6510            1  \n",
       "\n",
       "[6511 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train_aug.csv',sep=',',encoding='ISO-8859-1')\n",
    "test=pd.read_csv('CT22_english_1C_harmful_dev_test.tsv',sep='\\t')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.bar(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASyElEQVR4nO3dfbBc9X3f8fenwuA2doMIN6osZEtO5fGITiOoBlPH09om4ckzFZ6mjpgkVlw6clroxJP8URH+wHXKFKdN6HjqkiFGsZyklqkTD6pNSoRMxuNxeRCpDAiCdXnwIFVGCsIkHk9pod/+sb/bLtf36q7uw16pv/drZmfPfs/vnP2ew/LZveecXaWqkCT14a8sdwOSpPEx9CWpI4a+JHXE0Jekjhj6ktSRs5a7gZM5//zza926dcvdhiSdUR555JE/r6qJmead1qG/bt069u/fv9xtSNIZJcm3Z5vn4R1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSR+YM/SRvTPJQkm8mOZjkX7b6+iQPJplM8oUkZ7f6Oe3xZJu/bmhdN7b6U0muWLKtkiTNaJRv5L4CvL+qvpfkDcDXk/wR8MvAbVW1O8lvAdcBt7f7l6rqbybZCnwS+JkkG4GtwIXAW4D7kryjql5bgu0CYN2OryzVqnWGe+7WDyx3C9KymPOTfg18rz18Q7sV8H7gi62+C7imTW9pj2nzL0uSVt9dVa9U1bPAJHDJYmyEJGk0Ix3TT7IiyQHgGLAXeBr4blW92oYcBta06TXA8wBt/svAjwzXZ1hm+Lm2J9mfZP/x48dPeYMkSbMbKfSr6rWq2gRcwODT+TuXqqGquqOqNlfV5omJGX8kTpI0T6d09U5VfRe4H/i7wLlJps4JXAAcadNHgLUAbf4PAy8O12dYRpI0BqNcvTOR5Nw2/VeBnwKeZBD+P92GbQPubtN72mPa/K9WVbX61nZ1z3pgA/DQIm2HJGkEo1y9sxrYlWQFgzeJu6rqy0meAHYn+VfAfwPubOPvBH43ySRwgsEVO1TVwSR3AU8ArwLXL+WVO5KkHzRn6FfVo8BFM9SfYYarb6rqfwD/aJZ13QLccuptSpIWg9/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOzBn6SdYmuT/JE0kOJvmlVv94kiNJDrTb1UPL3JhkMslTSa4Yql/ZapNJdizNJkmSZnPWCGNeBX6lqv40yZuBR5LsbfNuq6p/Ozw4yUZgK3Ah8BbgviTvaLM/DfwUcBh4OMmeqnpiMTZEkjS3OUO/qo4CR9v0XyZ5ElhzkkW2ALur6hXg2SSTwCVt3mRVPQOQZHcba+hL0pic0jH9JOuAi4AHW+mGJI8m2ZlkZautAZ4fWuxwq81Wn/4c25PsT7L/+PHjp9KeJGkOI4d+kjcBfwB8rKr+Argd+DFgE4O/BH5jMRqqqjuqanNVbZ6YmFiMVUqSmlGO6ZPkDQwC//er6g8BquqFofm/DXy5PTwCrB1a/IJW4yR1SdIYjHL1ToA7gSer6jeH6quHhn0QeLxN7wG2JjknyXpgA/AQ8DCwIcn6JGczONm7Z3E2Q5I0ilE+6f8E8PPAY0kOtNqvAtcm2QQU8BzwUYCqOpjkLgYnaF8Frq+q1wCS3ADcC6wAdlbVwUXbEknSnEa5eufrQGaYdc9JlrkFuGWG+j0nW06StLT8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdWTO0E+yNsn9SZ5IcjDJL7X6eUn2JjnU7le2epJ8KslkkkeTXDy0rm1t/KEk25ZusyRJMxnlk/6rwK9U1UbgUuD6JBuBHcC+qtoA7GuPAa4CNrTbduB2GLxJADcD7wIuAW6eeqOQJI3HnKFfVUer6k/b9F8CTwJrgC3ArjZsF3BNm94CfK4GHgDOTbIauALYW1UnquolYC9w5WJujCTp5E7pmH6SdcBFwIPAqqo62mZ9B1jVptcAzw8tdrjVZqtPf47tSfYn2X/8+PFTaU+SNIeRQz/Jm4A/AD5WVX8xPK+qCqjFaKiq7qiqzVW1eWJiYjFWKUlqRgr9JG9gEPi/X1V/2MovtMM2tPtjrX4EWDu0+AWtNltdkjQmo1y9E+BO4Mmq+s2hWXuAqStwtgF3D9U/3K7iuRR4uR0Guhe4PMnKdgL38laTJI3JWSOM+Qng54HHkhxotV8FbgXuSnId8G3gQ23ePcDVwCTwfeAjAFV1IsmvAQ+3cZ+oqhOLsRGSpNHMGfpV9XUgs8y+bIbxBVw/y7p2AjtPpUFJ0uLxG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1JE5Qz/JziTHkjw+VPt4kiNJDrTb1UPzbkwymeSpJFcM1a9stckkOxZ/UyRJcxnlk/5ngStnqN9WVZva7R6AJBuBrcCFbZn/kGRFkhXAp4GrgI3AtW2sJGmMzpprQFV9Lcm6Ede3BdhdVa8AzyaZBC5p8yar6hmAJLvb2CdOvWVJ0nwt5Jj+DUkebYd/VrbaGuD5oTGHW222+g9Isj3J/iT7jx8/voD2JEnTzTf0bwd+DNgEHAV+Y7Eaqqo7qmpzVW2emJhYrNVKkhjh8M5MquqFqekkvw18uT08AqwdGnpBq3GSuiRpTOb1ST/J6qGHHwSmruzZA2xNck6S9cAG4CHgYWBDkvVJzmZwsnfP/NuWJM3HnJ/0k3weeC9wfpLDwM3Ae5NsAgp4DvgoQFUdTHIXgxO0rwLXV9VrbT03APcCK4CdVXVwsTdGknRyo1y9c+0M5TtPMv4W4JYZ6vcA95xSd5KkReU3ciWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI3OGfpKdSY4leXyodl6SvUkOtfuVrZ4kn0oymeTRJBcPLbOtjT+UZNvSbI4k6WRG+aT/WeDKabUdwL6q2gDsa48BrgI2tNt24HYYvEkANwPvAi4Bbp56o5Akjc+coV9VXwNOTCtvAXa16V3ANUP1z9XAA8C5SVYDVwB7q+pEVb0E7OUH30gkSUtsvsf0V1XV0Tb9HWBVm14DPD807nCrzVb/AUm2J9mfZP/x48fn2Z4kaSYLPpFbVQXUIvQytb47qmpzVW2emJhYrNVKkph/6L/QDtvQ7o+1+hFg7dC4C1pttrokaYzmG/p7gKkrcLYBdw/VP9yu4rkUeLkdBroXuDzJynYC9/JWkySN0VlzDUjyeeC9wPlJDjO4CudW4K4k1wHfBj7Uht8DXA1MAt8HPgJQVSeS/BrwcBv3iaqafnJYkrTE5gz9qrp2llmXzTC2gOtnWc9OYOcpdSdJWlR+I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOrKg0E/yXJLHkhxIsr/VzkuyN8mhdr+y1ZPkU0kmkzya5OLF2ABJ0ugW45P++6pqU1Vtbo93APuqagOwrz0GuArY0G7bgdsX4bklSadgKQ7vbAF2teldwDVD9c/VwAPAuUlWL8HzS5JmsdDQL+CPkzySZHurraqqo236O8CqNr0GeH5o2cOtJkkak7MWuPx7qupIkh8F9ib5s+GZVVVJ6lRW2N48tgO89a1vXWB7kqRhC/qkX1VH2v0x4EvAJcALU4dt2v2xNvwIsHZo8Qtabfo676iqzVW1eWJiYiHtSZKmmXfoJ/mhJG+emgYuBx4H9gDb2rBtwN1teg/w4XYVz6XAy0OHgSRJY7CQwzurgC8lmVrPf6yq/5LkYeCuJNcB3wY+1MbfA1wNTALfBz6ygOeWJM3DvEO/qp4BfnyG+ovAZTPUC7h+vs8nSVo4v5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdWeivbEpagHU7vrLcLeg09dytH1iS9fpJX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkbGHfpIrkzyVZDLJjnE/vyT1bKyhn2QF8GngKmAjcG2SjePsQZJ6Nu5P+pcAk1X1TFX9T2A3sGXMPUhSt8b9b+SuAZ4fenwYeNfwgCTbge3t4feSPDWm3ubrfODPl7uJEZwpfcIYes0nF2U1Z8o+tc/Fd7q/Rt8224zT7h9Gr6o7gDuWu49RJdlfVZuXu4+5nCl9wpnTq30urjOlTzizep1u3Id3jgBrhx5f0GqSpDEYd+g/DGxIsj7J2cBWYM+Ye5Ckbo318E5VvZrkBuBeYAWws6oOjrOHJXCmHIo6U/qEM6dX+1xcZ0qfcGb1+jqpquXuQZI0Jn4jV5I6YuhLUkcM/REkOS/J3iSH2v3KGcZsSvJfkxxM8miSnxma99kkzyY50G6bFrm/k/60RZJzknyhzX8wybqheTe2+lNJrljMvubR5y8neaLtv31J3jY077Wh/bekJ/9H6PMXkhwf6uefDM3b1l4nh5JsW8o+R+z1tqE+v5Xku0PzxrJPk+xMcizJ47PMT5JPtW14NMnFQ/PGvT/n6vVnW4+PJflGkh8fmvdcqx9Isn+pe523qvI2xw34dWBHm94BfHKGMe8ANrTptwBHgXPb488CP71Eva0AngbeDpwNfBPYOG3MPwN+q01vBb7Qpje28ecA69t6Vixjn+8D/lqb/qdTfbbH3xvTf+tR+vwF4N/PsOx5wDPtfmWbXrmcvU4b/88ZXDwx7n3694CLgcdnmX818EdAgEuBB5djf47Y67unemDwczIPDs17Djh/HPt0ITc/6Y9mC7CrTe8Crpk+oKq+VVWH2vR/B44BE2PobZSfthju/4vAZUnS6rur6pWqehaYbOtblj6r6v6q+n57+ACD73GM20J+KuQKYG9Vnaiql4C9wJVL1Ceceq/XAp9fwn5mVFVfA06cZMgW4HM18ABwbpLVjH9/ztlrVX2j9QLL9xpdEEN/NKuq6mib/g6w6mSDk1zC4JPX00PlW9qfhbclOWcRe5vppy3WzDamql4FXgZ+ZMRlx9nnsOsYfPqb8sYk+5M8kOSaJehvyqh9/sP23/OLSaa+cDjO/XlKz9cOla0HvjpUHtc+ncts2zHu/Xmqpr9GC/jjJI+0n5M5LZ12P8OwXJLcB/yNGWbdNPygqirJrNe5tk8ovwtsq6r/3co3MnizOJvB9b3/AvjEYvT9/6MkPwdsBv7+UPltVXUkyduBryZ5rKqennkNS+4/A5+vqleSfJTBX1HvX6ZeRrUV+GJVvTZUO5326RklyfsYhP57hsrvafvzR4G9Sf6s/eVwWvGTflNVP1lVf2uG293ACy3Mp0L92EzrSPLXga8AN7U/U6fWfbT96foK8Dss7iGUUX7a4v+OSXIW8MPAiyMuO84+SfKTDN5o/0HbXwBU1ZF2/wzwJ8BFy9VnVb041NtngL8z6rKL7FSebyvTDu2McZ/OZbbtOC1/tiXJ32bw331LVb04VR/an8eAL7F0h0oXZrlPKpwJN+Df8PoTub8+w5izgX3Ax2aYt7rdB/h3wK2L2NtZDE5wref/ncy7cNqY63n9idy72vSFvP5E7jMs3YncUfq8iMEhsQ3T6iuBc9r0+cAhTnLCcgx9rh6a/iDwQJs+D3i29buyTZ+3hK/LOXtt497J4CRjlmOftudYx+wnRz/A60/kPrQc+3PEXt/K4NzXu6fVfwh489D0N4Arl7rXeW3fcjdwJtwYHP/e1/7HuG/qhcfgEMRn2vTPAf8LODB029TmfRV4DHgc+D3gTYvc39XAt1pg3tRqn2DwaRngjcB/ai/Wh4C3Dy17U1vuKeCqJd6Pc/V5H/DC0P7b0+rvbvvvm+3+umXu818DB1s/9wPvHFr2H7f9PAl8ZAyvzZP22h5/nGkfNMa5Txn8hXG0/f9xmMFhkV8EfrHND4N/XOnp1svmZdyfc/X6GeClodfo/lZ/e9uX32yvjZuWutf53vwZBknqiMf0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqyP8BWJ6K2vkfosIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grouped=train.groupby(\"class_label\")\n",
    "label=grouped[\"class_label\"].count()\n",
    "plt.bar([0,1], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:  [('.', 469), ('the', 419), (',', 343), (':', 289), ('and', 272), ('to', 244), ('https', 224), ('of', 208), ('#', 180), ('vaccines', 174), ('a', 161), ('in', 141), ('@', 135), ('is', 129), ('for', 123), ('vaccine', 104), ('that', 92), ('are', 80), ('’', 71), ('COVID-19', 68), ('on', 67), ('not', 63), ('The', 60), ('have', 59), ('it', 59), ('you', 56), ('!', 51), ('people', 49), ('be', 48), (';', 48), ('has', 47), (\"'s\", 46), ('with', 45), ('will', 45), ('from', 45), ('this', 44), ('&', 42), ('about', 39), ('“', 39), ('they', 39), ('coronavirus', 38), ('can', 36), ('by', 36), ('”', 35), ('more', 35), ('Covid-19', 35), ('I', 33), ('-', 33), ('%', 32), ('COVID', 32)] \n",
      "\n",
      "N:  [('.', 4243), (':', 4041), ('the', 3986), ('and', 3574), (',', 3541), ('https', 3138), ('to', 3056), ('vaccines', 2316), ('of', 2126), ('#', 2104), ('@', 1763), ('COVID-19', 1528), ('in', 1430), ('a', 1256), ('for', 1250), ('vaccine', 1068), ('is', 993), ('are', 864), ('on', 805), ('that', 618), ('’', 604), ('with', 580), ('have', 566), ('The', 534), ('at', 481), ('be', 468), ('you', 459), ('from', 449), ('will', 449), (\"'s\", 431), ('it', 424), ('by', 423), ('about', 419), ('!', 403), ('more', 388), ('we', 383), ('I', 380), ('this', 379), (';', 370), ('Covid-19', 355), ('has', 349), ('as', 337), ('&', 333), ('s', 330), ('people', 319), ('get', 314), ('amp', 311), ('not', 298), ('COVID19', 294), ('our', 292)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y=train[train.class_label==1]\n",
    "N=train[train.class_label==0]\n",
    "\n",
    "Y_text=[]\n",
    "for i in Y[\"tweet_text\"]:\n",
    "    i=i.strip('\"')\n",
    "    Y_text.append(i)\n",
    "Y_text=\" \".join(Y_text)\n",
    "\n",
    "N_text=[]\n",
    "for i in N[\"tweet_text\"]:\n",
    "    i=i.strip('\"')\n",
    "    N_text.append(i)\n",
    "N_text=\" \".join(N_text)\n",
    "\n",
    "#stop_words=set(stopwords.words('english'))\n",
    "#stop_words.update({'.','@',',','#',':','!','A','I',')','(','//',\"'s\",'https','http','&',\"'m\",'The','?','By','-',';','...','[',']','|','s',\"'\",'/','*'})\n",
    "word_tokens=word_tokenize(Y_text)\n",
    "#final_text=[w for w in word_tokens if not w in stop_words]\n",
    "count=Counter(word_tokens)\n",
    "result=count.most_common(50)\n",
    "print(\"Y: \",result,'\\n')\n",
    "\n",
    "#stop_words=set(stopwords.words('english'))\n",
    "#stop_words.update({'.','@',',','#',':','!','A','I',')','(','//',\"'s\",'https','http','&',\"'m\",'The','?','By','-',';','...','[',']','|','s',\"'\",'/','*'})\n",
    "word_tokens=word_tokenize(N_text)\n",
    "#final_text=[w for w in word_tokens if not w in stop_words]\n",
    "count=Counter(word_tokens)\n",
    "result=count.most_common(50)\n",
    "print(\"N: \",result,'\\n')\n",
    "\n",
    "\n",
    "#{'.','the',',',':','and','to','https','of','#','a','in','for','that','’','is','are','on','it'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import EDA\n",
    "\n",
    "def text_augment(data,n): # n:replace # of words\n",
    "    t=EDA()\n",
    "    positive_df=data[data.class_label==1]\n",
    "    negative_df=data[data.class_label==0]\n",
    "    add_text=[]\n",
    "    if len(positive_df)>len(negative_df):\n",
    "        for i in range(math.floor(len(positive_df)/len(negative_df))-1):\n",
    "            for j in range(len(negative_df)):\n",
    "                result=t.synonym_replacement(negative_df.iloc[j]['tweet_text'],n)\n",
    "                add_text.append([result,negative_df.iloc[j]['class_label']])\n",
    "    if len(positive_df)<len(negative_df):\n",
    "        for i in range(math.floor(len(negative_df)/len(positive_df))-1):\n",
    "            for j in range(len(positive_df)):\n",
    "                result=t.synonym_replacement(positive_df.iloc[j]['tweet_text'],n)\n",
    "                add_text.append([result,positive_df.iloc[j]['class_label']])\n",
    "    new=pd.concat([data,pd.DataFrame(add_text,columns=['tweet_text','class_label'])])\n",
    "    return new\n",
    "\n",
    "train=train.iloc[:,3:5]\n",
    "train=text_augment(train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus to Word2Vec\n",
    "def all_corpus(data,stopword=False):\n",
    "    positive_df=data[data.class_label==1]\n",
    "    negative_df=data[data.class_label==0]\n",
    "    positive_df=positive_df.dropna(subset=[\"tweet_text\"])\n",
    "    negative_df=negative_df.dropna(subset=[\"tweet_text\"])\n",
    "    positive_df=positive_df[\"tweet_text\"].reset_index()\n",
    "    for i in range(len(positive_df)):\n",
    "        word_tokens1=word_tokenize(positive_df['tweet_text'][i].lower())\n",
    "        final_text1=word_tokens1\n",
    "        if stopword==True:\n",
    "            stop_words=set(stopwords.words('english'))\n",
    "            final_text1=[w for w in word_tokens1 if not w in stop_words]\n",
    "        positive_df['tweet_text'][i]=final_text1\n",
    "    positive_df=positive_df.drop('index',axis=1)\n",
    "    positive_df['class_label']=np.repeat(1,len(positive_df))\n",
    "    negative_df=negative_df[\"tweet_text\"].reset_index()\n",
    "    for i in range(len(negative_df)):\n",
    "        word_tokens2=word_tokenize(negative_df['tweet_text'][i].lower())\n",
    "        final_text2=word_tokens2\n",
    "        if stopword==True:\n",
    "            stop_words=set(stopwords.words('english'))\n",
    "            final_text2=[w for w in word_tokens2 if not w in stop_words]\n",
    "        negative_df['tweet_text'][i]=final_text2\n",
    "    negative_df=negative_df.drop('index',axis=1)\n",
    "    negative_df['class_label']=np.repeat(0,len(negative_df))\n",
    "    ddf=pd.concat([positive_df,negative_df])\n",
    "    return ddf\n",
    "\n",
    "def text_to_index(corpus_all,word2idx):\n",
    "    new_corpus=[]\n",
    "    for doc in corpus_all:\n",
    "        new_doc=[]\n",
    "        for word in doc:\n",
    "            try:\n",
    "                new_doc.append(word2idx[word])\n",
    "            except:\n",
    "                new_doc.append(0)\n",
    "        new_corpus.append(new_doc)\n",
    "    return np.array(new_corpus)\n",
    "\n",
    "# model\n",
    "def RNN_model(embedding_layer):\n",
    "    optimizer=Adam(learning_rate=0.00001)\n",
    "    model=Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(SimpleRNN(64))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def GRU_model(embedding_layer):\n",
    "    optimizer=Adam(learning_rate=0.00001)\n",
    "    model=Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(GRU(64))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def LSTM_model(embedding_layer):\n",
    "    optimizer=Adam(learning_rate=0.00001)\n",
    "    model=Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(LSTM(64))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# plot\n",
    "def chart(fit_details, metric):\n",
    "    plt.plot(fit_details.history[metric])\n",
    "    plt.plot(fit_details.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YINGJH~1\\AppData\\Local\\Temp/ipykernel_26656/552860300.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  positive_df['tweet_text'][i]=final_text1\n",
      "C:\\Users\\YINGJH~1\\AppData\\Local\\Temp/ipykernel_26656/552860300.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  negative_df['tweet_text'][i]=final_text2\n",
      "C:\\Users\\YINGJH~1\\AppData\\Local\\Temp/ipykernel_26656/552860300.py:40: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(new_corpus)\n"
     ]
    }
   ],
   "source": [
    "random.seed(200)\n",
    "np.random.seed(200)\n",
    "tf.random.set_seed(200)\n",
    "\n",
    "stopword=True\n",
    "train_data=train\n",
    "test_data=test\n",
    "train_data=all_corpus(train_data,stopword=stopword)\n",
    "test_data=all_corpus(test_data,stopword=stopword)\n",
    "corpus=pd.concat([train_data.tweet_text,test_data.tweet_text])\n",
    "w2v_model=Word2Vec(corpus,vector_size=500,epochs=10,sg=1)\n",
    "embedding_matrix=np.zeros((len(w2v_model.wv.key_to_index.items())+1,w2v_model.vector_size))\n",
    "#w2v_model=gensim.models.KeyedVectors.load_word2vec_format('C:/Users/Ying Jhu/Desktop/y_360W_cbow_2D_100dim_2020v1.bin',unicode_errors='ignore',binary=True)\n",
    "#embedding_matrix=np.zeros((len(w2v_model.key_to_index.items())+1,w2v_model.vector_size))\n",
    "word2idx={}\n",
    "vocab_list=[(word,w2v_model.wv[word]) for word,_ in w2v_model.wv.key_to_index.items()]\n",
    "#vocab_list=[(word,w2v_model[word]) for word,_ in w2v_model.key_to_index.items()]\n",
    "for i,vocab in enumerate(vocab_list):\n",
    "    word,vec=vocab\n",
    "    embedding_matrix[i+1]=vec\n",
    "    word2idx[word]=i+1\n",
    "embedding_layer=Embedding(input_dim=embedding_matrix.shape[0],output_dim=embedding_matrix.shape[1],weights=[embedding_matrix],trainable=True)\n",
    "np.random.seed(200)\n",
    "train_data=train_data.sample(frac=1).reset_index(drop=True)\n",
    "np.random.seed(200)\n",
    "test_data=test_data.sample(frac=1).reset_index(drop=True)\n",
    "X=text_to_index(train_data.tweet_text,word2idx)\n",
    "X=pad_sequences(X,maxlen=60,padding='post')\n",
    "Y=train_data.class_label\n",
    "X_test=text_to_index(test_data.tweet_text,word2idx)\n",
    "X_test=pad_sequences(X_test,maxlen=60,padding='post')\n",
    "Y_test=test_data.class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 3s 12ms/step - loss: 0.6935 - accuracy: 0.4896 - val_loss: 0.6929 - val_accuracy: 0.5004\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6931 - accuracy: 0.4940 - val_loss: 0.6929 - val_accuracy: 0.4973\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6928 - accuracy: 0.4994 - val_loss: 0.6928 - val_accuracy: 0.5027\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6929 - accuracy: 0.4988 - val_loss: 0.6927 - val_accuracy: 0.5019\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6929 - accuracy: 0.5081 - val_loss: 0.6927 - val_accuracy: 0.5012\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6927 - accuracy: 0.5115 - val_loss: 0.6927 - val_accuracy: 0.5012\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6926 - val_accuracy: 0.5012\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6925 - accuracy: 0.5083 - val_loss: 0.6926 - val_accuracy: 0.5012\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6926 - accuracy: 0.5063 - val_loss: 0.6926 - val_accuracy: 0.5012\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6924 - accuracy: 0.5131 - val_loss: 0.6926 - val_accuracy: 0.5012\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5094 - val_loss: 0.6925 - val_accuracy: 0.5012\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6925 - accuracy: 0.5098 - val_loss: 0.6925 - val_accuracy: 0.5012\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5088 - val_loss: 0.6925 - val_accuracy: 0.5012\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5123 - val_loss: 0.6924 - val_accuracy: 0.5012\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6923 - accuracy: 0.5132 - val_loss: 0.6924 - val_accuracy: 0.5019\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6921 - accuracy: 0.5113 - val_loss: 0.6924 - val_accuracy: 0.5019\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6922 - accuracy: 0.5100 - val_loss: 0.6924 - val_accuracy: 0.5019\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6920 - accuracy: 0.5081 - val_loss: 0.6924 - val_accuracy: 0.5019\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 1s 9ms/step - loss: 0.6921 - accuracy: 0.5090 - val_loss: 0.6924 - val_accuracy: 0.5019\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6921 - accuracy: 0.5090 - val_loss: 0.6923 - val_accuracy: 0.5012\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6921 - accuracy: 0.5123 - val_loss: 0.6923 - val_accuracy: 0.5019\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6920 - accuracy: 0.5069 - val_loss: 0.6923 - val_accuracy: 0.5019\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5086 - val_loss: 0.6923 - val_accuracy: 0.5019\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6921 - accuracy: 0.5086 - val_loss: 0.6923 - val_accuracy: 0.5019\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6921 - accuracy: 0.5096 - val_loss: 0.6922 - val_accuracy: 0.5019\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5071 - val_loss: 0.6922 - val_accuracy: 0.5019\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6921 - accuracy: 0.5086 - val_loss: 0.6922 - val_accuracy: 0.5019\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5100 - val_loss: 0.6922 - val_accuracy: 0.5019\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5106 - val_loss: 0.6922 - val_accuracy: 0.5019\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6918 - accuracy: 0.5084 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5108 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5096 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5106 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5098 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6916 - accuracy: 0.5108 - val_loss: 0.6921 - val_accuracy: 0.5019\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6916 - accuracy: 0.5106 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6917 - accuracy: 0.5100 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6915 - accuracy: 0.5111 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6915 - accuracy: 0.5129 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6914 - accuracy: 0.5106 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5115 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6914 - accuracy: 0.5119 - val_loss: 0.6920 - val_accuracy: 0.5019\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5142 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5115 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6911 - accuracy: 0.5117 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6913 - accuracy: 0.5129 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6912 - accuracy: 0.5117 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6911 - accuracy: 0.5088 - val_loss: 0.6919 - val_accuracy: 0.5019\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6912 - accuracy: 0.5123 - val_loss: 0.6918 - val_accuracy: 0.5019\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6910 - accuracy: 0.5109 - val_loss: 0.6918 - val_accuracy: 0.5027\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6910 - accuracy: 0.5115 - val_loss: 0.6918 - val_accuracy: 0.5027\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6909 - accuracy: 0.5132 - val_loss: 0.6918 - val_accuracy: 0.5027\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6911 - accuracy: 0.5104 - val_loss: 0.6918 - val_accuracy: 0.5019\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6910 - accuracy: 0.5115 - val_loss: 0.6918 - val_accuracy: 0.5019\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6908 - accuracy: 0.5123 - val_loss: 0.6918 - val_accuracy: 0.5027\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6910 - accuracy: 0.5115 - val_loss: 0.6918 - val_accuracy: 0.5027\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6908 - accuracy: 0.5123 - val_loss: 0.6917 - val_accuracy: 0.5027\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6908 - accuracy: 0.5125 - val_loss: 0.6917 - val_accuracy: 0.5027\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6906 - accuracy: 0.5121 - val_loss: 0.6917 - val_accuracy: 0.5027\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6907 - accuracy: 0.5140 - val_loss: 0.6916 - val_accuracy: 0.5027\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6906 - accuracy: 0.5119 - val_loss: 0.6917 - val_accuracy: 0.5027\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6904 - accuracy: 0.5131 - val_loss: 0.6916 - val_accuracy: 0.5027\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6905 - accuracy: 0.5131 - val_loss: 0.6916 - val_accuracy: 0.5042\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6905 - accuracy: 0.5117 - val_loss: 0.6915 - val_accuracy: 0.5050\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6902 - accuracy: 0.5136 - val_loss: 0.6915 - val_accuracy: 0.5042\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6904 - accuracy: 0.5127 - val_loss: 0.6915 - val_accuracy: 0.5050\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6902 - accuracy: 0.5134 - val_loss: 0.6915 - val_accuracy: 0.5058\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6903 - accuracy: 0.5161 - val_loss: 0.6914 - val_accuracy: 0.5058\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6901 - accuracy: 0.5140 - val_loss: 0.6914 - val_accuracy: 0.5058\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6901 - accuracy: 0.5142 - val_loss: 0.6914 - val_accuracy: 0.5073\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6901 - accuracy: 0.5144 - val_loss: 0.6914 - val_accuracy: 0.5073\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6901 - accuracy: 0.5173 - val_loss: 0.6913 - val_accuracy: 0.5096\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6900 - accuracy: 0.5121 - val_loss: 0.6912 - val_accuracy: 0.5096\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6898 - accuracy: 0.5169 - val_loss: 0.6912 - val_accuracy: 0.5096\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6899 - accuracy: 0.5179 - val_loss: 0.6911 - val_accuracy: 0.5096\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6897 - accuracy: 0.5148 - val_loss: 0.6911 - val_accuracy: 0.5096\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6894 - accuracy: 0.5150 - val_loss: 0.6910 - val_accuracy: 0.5104\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6894 - accuracy: 0.5182 - val_loss: 0.6909 - val_accuracy: 0.5111\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6898 - accuracy: 0.5179 - val_loss: 0.6909 - val_accuracy: 0.5111\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6895 - accuracy: 0.5223 - val_loss: 0.6907 - val_accuracy: 0.5127\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6893 - accuracy: 0.5223 - val_loss: 0.6907 - val_accuracy: 0.5119\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6891 - accuracy: 0.5248 - val_loss: 0.6905 - val_accuracy: 0.5142\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6889 - accuracy: 0.5228 - val_loss: 0.6903 - val_accuracy: 0.5173\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6888 - accuracy: 0.5240 - val_loss: 0.6901 - val_accuracy: 0.5173\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6883 - accuracy: 0.5284 - val_loss: 0.6896 - val_accuracy: 0.5242\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6880 - accuracy: 0.5344 - val_loss: 0.6890 - val_accuracy: 0.5280\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6870 - accuracy: 0.5403 - val_loss: 0.6877 - val_accuracy: 0.5579\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6850 - accuracy: 0.5641 - val_loss: 0.6841 - val_accuracy: 0.5863\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.6740 - accuracy: 0.6415 - val_loss: 0.6541 - val_accuracy: 0.7084\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.5607 - accuracy: 0.7961 - val_loss: 0.4692 - val_accuracy: 0.8480\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.4395 - accuracy: 0.8677 - val_loss: 0.4088 - val_accuracy: 0.8703\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.3824 - accuracy: 0.8881 - val_loss: 0.3691 - val_accuracy: 0.8787\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.3358 - accuracy: 0.9044 - val_loss: 0.3363 - val_accuracy: 0.8979\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.3018 - accuracy: 0.9128 - val_loss: 0.3093 - val_accuracy: 0.8987\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2721 - accuracy: 0.9219 - val_loss: 0.2906 - val_accuracy: 0.9079\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2519 - accuracy: 0.9268 - val_loss: 0.2822 - val_accuracy: 0.9033\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2349 - accuracy: 0.9332 - val_loss: 0.2671 - val_accuracy: 0.9117\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.2139 - accuracy: 0.9418 - val_loss: 0.2552 - val_accuracy: 0.9194\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1995 - accuracy: 0.9474 - val_loss: 0.2453 - val_accuracy: 0.9240\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 1s 8ms/step - loss: 0.1837 - accuracy: 0.9526 - val_loss: 0.2399 - val_accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAHgCAYAAADOnJaPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABDF0lEQVR4nO3deXxU1f3/8dfJzGQjCWSBsO8gooAsCop1ra1tVVxq0VrrbrV1ae1ma7+t39b2133RWr9Sv1qtW11K61etVgWLihvIJmGLbAmEQPZ1JrOc3x/3JkxCBgbMMCHzfj4eeZC5c2fmzHWcdz7nnHuusdYiIiIi+0pLdgNERER6K4WkiIhIDApJERGRGBSSIiIiMSgkRUREYlBIioiIxOBNdgMOVlFRkR09enSymyEiIn3E8uXLq6y1A7u774gLydGjR7Ns2bJkN0NERPoIY8y2WPepu1VERCQGhaSIiEgMCkkREZEYjrgxye4Eg0HKy8vx+/3JbooAmZmZDB8+HJ/Pl+ymiIh8LH0iJMvLy8nNzWX06NEYY5LdnJRmraW6upry8nLGjBmT7OaIiHwsfaK71e/3U1hYqIDsBYwxFBYWqqoXkT6hT4QkoIDsRfTfQkT6ij4TkiIiIj1NIXmECYVCyW6CiEjKUEj2oPPPP5+ZM2dyzDHHsGDBAgBeeuklZsyYwbRp0zjzzDMBaGpq4qqrrmLKlClMnTqVZ599FoCcnJyO53rmmWe48sorAbjyyiu54YYbmD17Nt/5znd47733OPHEE5k+fTonnXQSGzZsACAcDvOtb32LY489lqlTp3LPPfewaNEizj///I7nfeWVV7jgggsOw9EQETny9YnZrdH++//WUrKzoUefc/LQPH507jEH3O/BBx+koKCA1tZWjj/+eObNm8d1113HkiVLGDNmDDU1NQD85Cc/oX///qxZswaA2traAz53eXk5S5cuxePx0NDQwBtvvIHX6+XVV1/l+9//Ps8++ywLFixg69atrFy5Eq/XS01NDfn5+Xz1q19lz549DBw4kIceeoirr7764x0QEZEU0edCMpnuvvtuFi5cCEBZWRkLFizglFNO6TgVoqCgAIBXX32VJ598suNx+fn5B3zuiy++GI/HA0B9fT1XXHEFmzZtwhhDMBjseN4bbrgBr9fb6fUuv/xyHn30Ua666irefvttHnnkkR56xyIifVufC8l4Kr5EeP3113n11Vd5++23yc7O5rTTTuO4445j/fr1cT9H9KzQrqdQ9OvXr+P3//qv/+L0009n4cKFbN26ldNOO22/z3vVVVdx7rnnkpmZycUXX9wRoiIisn8ak+wh9fX15Ofnk52dzfr163nnnXfw+/0sWbKELVu2AHR0t5511lnce++9HY9t724tLi5m3bp1RCKRjoo01msNGzYMgL/85S8d28866yzuv//+jsk97a83dOhQhg4dyl133cVVV13Vc29aRKSPU0j2kLPPPptQKMTRRx/N7bffzpw5cxg4cCALFizgwgsvZNq0acyfPx+AH/zgB9TW1nLssccybdo0Fi9eDMDPf/5zzjnnHE466SSGDBkS87W+853v8L3vfY/p06d3mu167bXXMnLkSKZOncq0adN4/PHHO+677LLLGDFiBEcffXSCjoCISN9jrLXJbsNBmTVrlu16Pcl169bpy/8AbrrpJqZPn84111xzWF5P/01E5EhhjFlurZ3V3X2qJFPAzJkzWb16NV/60peS3RQRkR6xtar5sLyOQjIFLF++nCVLlpCRkZHspoiIfGxPvV/Gmb/9D+9urk74aykkRUTkiPHO5mq+v3ANJ40rZMaoA58+93EpJEVE5IiwtaqZGx5dzqjCbP74xRn4PImPMIWkiIj0evUtQa5++H0M8OCVx9M/6/Bc1F1nlYuISK8WCkf42uMfUFbTwqPXzGZUYb8DP6iHKCRFRKRX+9XLG3iztIpffn4qs8cWHtbXVndrEkRf7UNERGJ7cU0F9y/ZzOVzRvGFWSMO++srJFOYrk0pIr1Z6e5Gvv30KqaPHMB/nTM5KW3oe92t/7oddq3p2eccPAU+8/OYd99+++2MGDGCr33tawDceeedeL1eFi9eTG1tLcFgkLvuuot58+Yd8KWampqYN29et4975JFH+PWvf40xhqlTp/LXv/6VyspKbrjhBjZv3gzAfffdx9ChQznnnHP48MMPAfj1r39NU1MTd955Z8fC62+++SaXXnopEydO5K677qKtrY3CwkIee+wxiouLaWpq4uabb2bZsmUYY/jRj35EfX09q1ev5ve//z0Af/7znykpKeF3v/vdxzm6IiL7aAqE+Mpfl5OV7uFPl80g3Zucmq7vhWQSzJ8/n69//esdIfnUU0/x8ssvc8stt5CXl0dVVRVz5szhvPPO63Slj+5kZmaycOHCfR5XUlLCXXfdxdKlSykqKupYvPyWW27h1FNPZeHChYTDYZqamg54fcq2tjbal/arra3lnXfewRjDAw88wC9/+Ut+85vfdHvNS5/Px09/+lN+9atf4fP5eOihh7j//vs/7uETEdnHD//xIVurnYk6Q/pnJa0dfS8k91PxJcr06dPZvXs3O3fuZM+ePeTn5zN48GC+8Y1vsGTJEtLS0tixYweVlZUMHjx4v89lreX73//+Po9btGgRF198MUVFRcDea0UuWrSo4/qQHo+H/v37HzAk2xdaB+dizvPnz6eiooK2traOa1/GuublGWecwfPPP8/RRx9NMBhkypQpB3m0RET2b/2uBv6+Ygc3njaOE8cd3ok6XfW9kEySiy++mGeeeYZdu3Yxf/58HnvsMfbs2cPy5cvx+XyMHj16n2tEdudQHxfN6/USiUQ6bu/v2pQ333wzt912G+eddx6vv/46d955536f+9prr+VnP/sZkyZN0mW3RCQh/vDqJnIzvHzllLHJboom7vSU+fPn8+STT/LMM89w8cUXU19fz6BBg/D5fCxevJht27bF9TyxHnfGGWfw9NNPU13trFXY3t165plnct999wEQDoepr6+nuLiY3bt3U11dTSAQ4Pnnn9/v67Vfm/Lhhx/u2B7rmpezZ8+mrKyMxx9/nEsvvTTewyMiEpe1O+v514e7uOrkMQzITk92cxSSPeWYY46hsbGRYcOGMWTIEC677DKWLVvGlClTeOSRR5g0aVJczxPrcccccwx33HEHp556KtOmTeO2224D4A9/+AOLFy9mypQpzJw5k5KSEnw+Hz/84Q854YQTOOuss/b72nfeeScXX3wxM2fO7OjKhdjXvAT4whe+wNy5czu6YEVEesofXt1EbqaXa04ek+ymALqepByCc845h2984xuceeaZMffRfxMROVgf7qjnnHve5OufnMDXPznxsL2uricpPaKuro6JEyeSlZW134AUETkUv391E3mZXq7uJVUkaOJO0qxZs4bLL7+807aMjAzefffdJLXowAYMGMDGjRuT3QwR6YNWl9fx6rpKvnnWRPIyD8/i5fFQSCbJlClTWLlyZbKbISKSdMFwhO8vXENBv3SunDs62c3ppM90tx5pY6t9mf5biMjBuGdRKR/uaOBnF0whtxdVkdBHQjIzM5Pq6mp9OfcC1lqqq6vJzMxMdlNE5AiwsqyOexeXcuGMYZx97P4XW0mGPtHdOnz4cMrLy9mzZ0+ymyI4f7QMHz482c0QkV6utS3MbX9bSXFuBneed0yym9OtPhGSPp+vYzk1ERE5MvzipfVsrmrm8Wtn96rJOtH6RHeriIgcWf61poK/LN3KVXNHc9L4ogM/IEkUkiIiclgt31bDrX9bycxR+Xz37PhWI0uWPtHdKiIiR4YtVc1c+/Ayhg3I4s9fnkWmz3PgBwVbYfHPIBKCQZOheDIMPBrSsxPeXoWkiIgcFtVNAa586D3SjOEvVx1PQb84FjAPtcFTV8Cmf4M3E0Kt7h0GrnkFRhyf0DYrJEVEJOGstdzw6HJ21ft54vo5jCrsd+AHRcKw8HrY9DKc8zuYcQXUboXKtbC7BIomJLzdCkkREUm4Ret38/7WWn5+4RRmjIzjCkKRCDx3C6xdCGf9BGZd7WwvHOf8TD4vsQ12aeKOiIgklLWWexaVMqIgi4tmxnkO9aIfw8pH4dTvwtxbEtvA/VBIiohIQr1VWs3KsjpuPHU8Pk8csVNZAm/9AaZ/CU77XuIbuB8KSRERSah7Fm1icF4mF80cduCdrYV/3wEZuU43qzGJb+B+KCRFRCRh3ttSw7tbarj+lLFkeOM43WPTK/DRIjj1dsguSHwDD0AhKSIiCfPHxaUU9kvn0hNGHnjncBBe/j4Ujofjr0184+KgkBQRkYRYXV7Hko17uPYTY8lKj6OKXPYgVG+CT/0UvHGcQ3kYKCRFRCQh7n6tlLxML1+aE0cV2VLjrKoz9jSY+OmEty1eCkkREelxK8vqeHVdJdefMja+Cym/8RsINMCnf5b0yTrRFJIiItLjfvPvDRT0S+fKuXFcxrBhJ7z/AEy7FIp713UlFZIiItKj3t1czRubqrjx1HHkZMSxsNsbv3EWLz/1O4lv3EFSSIqISI+x1vKbf29kUG4Gl584au8dkTA8Ph9e/4VzLmS72m2w/GGY8WXIH33Y23sgWrtVRER6zBubqnhvaw0/mXdM58tglfwTNr7k/KSlwSnfdrb/55dgom73MgpJERHpEU4VuYFhA7L4wvEjou+AN3/rnP84bCYsugvSc2H8J2HV4zD7RsgbmryG74dCUkREesTrG/ewqryeX140tfPqOqWvwa41MO9emHoJtDXDS9+FoqPAmwUnfyN5jT6AhI5JGmPONsZsMMaUGmNu7+b+UcaY14wxq40xrxtj4lweXkREeptXSirJyfBywYwua7S+8RvIGwZTvgAeL3z+QRh3BlRtgDk3QM7A5DQ4DgkLSWOMB7gX+AwwGbjUGDO5y26/Bh6x1k4Ffgz8v0S1R0REEuut0irmjC3ofKWP7e/A9qVw0s17V9HxZsD8x+Dcu+ET30xOY+OUyEryBKDUWrvZWtsGPAnM67LPZGCR+/vibu4XEZEjQFlNC9uqW5g7vqjzHW/8FrILndmr0dKzYeYVkN7v8DXyECQyJIcBZVG3y91t0VYBF7q/XwDkGmMKE9gmERFJgDdLqwD4xISokNy1Bja97EzM6eVhGEuyJ+58C/ijMeZKYAmwAwh33ckYcz1wPcDIkXGsASgiIofVm6VVjM6NMG7zo/D2h86Fk/esh/QcOKF3XNHjUCQyJHcAUXOAGe5u62Ct3YlbSRpjcoCLrLV1XZ/IWrsAWAAwa9Ys2/V+ERFJnkjEsrS0ih8NfAfz0h8huwiKJ8OMK+CYCyArP9lNPGSJDMn3gQnGmDE44XgJ8MXoHYwxRUCNtTYCfA94MIHtERGRBCipaKC2JcjxaRtgwEj4+ppkN6nHJGxM0lobAm4CXgbWAU9Za9caY35sjDnP3e00YIMxZiNQDPw0Ue0REZHEeGNTFWAZ3LAKRsxJdnN6VELHJK21LwIvdtn2w6jfnwGeSWQbREQksd4qreKUga14GnfDyNnJbk6P0gLnIiJyyPzBMO9treGConJnwwiFpIiICADLttbSFopwvGeTM5N1UNc1Y45sCkkRETlkb5ZW4fMYhjSuhuGzIM1z4AcdQRSSIiJyyN4s3cOJwzPw7F7b57paQSEpIiKHqK6ljbU7Gzh/4C6wERhxQrKb1OMUkiIickhWbK/DWjjeuwkwMPz4ZDepxykkRUTkkKwoqyPNwJD6Vc6Encz+yW5Sj1NIiojIIVlZVsdRg/rh3bmsT3a1gkJSREQOgbWWVWV1fLq4DgINfXLSDigkRUTkEGytbqG+Ncjc9I+cDaokRUREHCvLagGY2FbiXPWjYGySW5QYCkkRETloK7fX0S/dQ17VBzByDhiT7CYlhEJSREQO2sqyOs4Y3Iqp2dwnT/1op5AUEZGD4g+GKalo4Bq7EDzpMOXzyW5SwigkRUTkoJRUNDA0UsHUqudh1tXQf3iym5QwCkkRETkoK7fX8XXvsxhPOpx8W7Kbk1AKSREROSi7Slcwz7MUM/srkFuc7OYklEJSREQOykllCwiYLJh7a7KbknAKSRERiVv95vc5Lfw2a0d9CbILkt2chFNIiohI3Npe+3/U2X7YOV9NdlMOC4WkiIjEJxJmQMVb/CN8MpPHjEh2aw4LhaSIiMSnahO+iJ89eZPpl+FNdmsOC4WkiIjEp2IVAOHiKUluyOGjkBQRkfhUrKKVdAL9xyW7JYeNQlJEROJiK1ayLjKKfllZyW7KYaOQFBGRA4tEoGIVH0ZGk5eVGuORoJAUEZF41G7BtDXxoR1NbqYv2a05bBSSIiJyYBUrAVgbGUOeQlJERCRKxSoiaelstMPV3SoiItJJxSqa+k8kiFfdrSIiIh2shZ0rqck7GoC8TFWSIiIijrrt4K9jV7+JAKokRUREOrgr7ZRltIekKkkRERFHxSowHrZ6R5HhTSPT50l2iw4bhaSIiOxfxSoYdDQ1gdSatAMKSRER2R9rnXMkh0yj0R9MqdM/QCEpIiL701gBzXtgyDQa/CFVkiIiIh3cSTsMmUZDazClTv8AhaSIiOxPxSrAQPGxbnerKkkRERFH027ILoCMHBr8IVWSIiIiHUIB8DrXj2z0B1NqcXNQSIqIyP6E/ODNIBAK4w9GUmohAVBIiojI/oT84M2k0R8C0JikiIhIh1AAvBl7Q1LdrSIiIi63kmxoDQKptW4rKCRFRGR/ulaS6m4VERFxtVeSflWSIiIinbmVZHt3q8YkRURE2ml2q4iISAztlaQ/SJqBfumpcy1JUEiKiMj+RFWSuZk+jDHJbtFhpZAUEZHYosYkU23SDigkRUQkFms7zW5NtUk7oJAUEZFYwkHAumOSIfKyVEmKiIg4Qn7nX3fFnVxVkiIiIq5QwPnXXXFH3a0iIiLtoitJvybuiIiI7OVWkhFPBk2BUMotJAAKSRERicWtJP34sBbyVEmKiIi43EqyJeyEo8YkRURE2rmVZHPEDUmdAiIiIuJyQ7Ip5KzXqlNARERE2rndrU3qbhUREenCrSQbQk5UqLtVRESknVtJ1repu1VERKSz9koy2B6SqiRFREQcbiVZGzRk+Tz4PKkXGan3jkVEJD5uJVnX5knJ8UhQSIqISCxuJVkTSM2ZraCQFBGRWEJ+SPNR77cpOR4JCkkREYklFABvJo3+YEoubg4KSRERiSXkB28GDf5QSp7+AQpJERGJJbqSVHeriIhIlJAf682goTU1ryUJCkkREYnFDcm2cEQTd0RERDoJBQinpQM6BSQhjDFnG2M2GGNKjTG3d3P/SGPMYmPMCmPMamPMZxPZHhEROQghPyGTAaTmknSQwJA0xniAe4HPAJOBS40xk7vs9gPgKWvtdOAS4E+Jao+IiBykUICgcStJjUn2uBOAUmvtZmttG/AkMK/LPhbIc3/vD+xMYHtERORghPy0GSccU3V2ayLf9TCgLOp2OTC7yz53Av82xtwM9AM+mcD2iIjIwQgFaPNoTDKZLgX+Yq0dDnwW+KsxZp82GWOuN8YsM8Ys27Nnz2FvpIhISgr5CVi3klR3a4/bAYyIuj3c3RbtGuApAGvt20AmUNT1iay1C6y1s6y1swYOHJig5oqISCehAK3W6XDUxJ2e9z4wwRgzxhiTjjMx57ku+2wHzgQwxhyNE5IqFUVEeoOQn1brw5vmXE8yFSUsJK21IeAm4GVgHc4s1rXGmB8bY85zd/smcJ0xZhXwBHCltdYmqk0iInIQQgFaI176ZXgxxiS7NUmR0PrZWvsi8GKXbT+M+r0EmJvINoiIyCGw1hmTxEeGN9nTV5Indd+5iIjEFg4CFr/1keFL3ahI3XcuIiKxhfwA+PGR7kndqEjddy4iIrGFAgD4Iz7Svak5aQcUkiIi0h23kmy1PtI1JikiIhLFrSRbI14y1N0qIiISxa0kWyJeTdwRERHppL2StF5N3BEREekkqpLUmKSIiEg0NySbwpq4IyIi0pnb3doc9mjFHRERkU7cSrI5rO5WERGRzjoqSS/pHi0mICIispdbSTaGPKokRUREOnErycawV2OSIiIinbiVZADNbhUREenMrSTbdD1JERGRLkJ+bJqPCGmqJEVERDoJBbDeDAAtSyciItJJyI/1OCGpBc5FRESihQJEPO2VpM6TFBER2SvkJ5LmhqTGJEVERKKE/IQ96YBCUkREpLNQgLBbSeoUEBERkWghP+E0VZKp+85FRCS2UIBQmk4BSd13LiIisYX8hIxTSaq7VUREJFoo0BGS6m4VERGJFvITTGuvJHWepIiIyF6hAEFUSabuOxcRkdhCftqMD1BIioiIdBYK0IYbkprdKiIi4rLWqSRJxxjweUyyW5Q0CkkREeksHAQsfnyke9IwRiEpIiLiCPkBCOBL6fFIUEiKiEhXoQAAfutL6YUEQCEpIiJduZWkE5Kpe44kKCRFRKSrqEpS3a0iIiLR3EqyNeJN6dM/QCEpIiJduZVkqypJhaSIiHThVpItEa9CMtkNEBGRXiYqJDW7VUREJJrb3apKMs6QNMb83RjzOWNMah8tEZFU4FaSzWFN3In33f8J+CKwyRjzc2PMUQlsk4iIJJNbSTaHVUnG9e6tta9aay8DZgBbgVeNMUuNMVcZ415LRURE+ga3kmwKe7WYQLw7GmMKgSuBa4EVwB9wQvOVhLRMRESSw60km8KelK8kvfHsZIxZCBwF/BU411pb4d71N2PMskQ1TkREkqC9kgxpdmtcIQncba1d3N0d1tpZPdgeERFJNreSbAynpXwlGe+7n2yMGdB+wxiTb4z5amKaJCIiSRXyQ5oPfwjNbo1zv+ustXXtN6y1tcB1CWmRiIgkVyiA9WYSsaR8d2u8795joi5NbYzxAOmJaZKIiCRVyA/eDICU726Nd0zyJZxJOve7t7/ibhMRkb4mFMB6FJIQf0h+FycYb3RvvwI8kJAWiYhIcoX8RBSSQJwhaa2NAPe5PyIi0pdFhWSqLyYQ73mSE4D/B0wGMtu3W2vHJqhdIiKSLKGAKklXvO/+IZwqMgScDjwCPJqoRomISBKF/ITTnLmZOgUkPlnW2tcAY63dZq29E/hc4polIiJJEwoQTmvvbk3tkIx34k7AvUzWJmPMTcAOICdxzRIRkaQJ+Ql7cwGFZLzv/lYgG7gFmAl8CbgiUY0SEZEkCgUItXe3pnhIHrCSdBcOmG+t/RbQBFyV8FaJiEjyhPyEjEIS4qgkrbVh4OTD0BYREekNQgGCCkkg/jHJFcaY54Cngeb2jdbavyekVSIikjwh/96QTPHZrfGGZCZQDZwRtc0CCkkRkb4mqpLM8GkxgQOy1mocUkQkFVgLIT9tqiSB+FfceQincuzEWnt1j7dIRESSJxwELG34AI1Jxtvd+nzU75nABcDOnm+OiIgkVcgPQMANyVQ/TzLe7tZno28bY54A3kxIi0REJHlCAWBvSKZ6d+uhvvsJwKCebIiIiPQC7ZWk9eHzGNLSTJIblFzxjkk20nlMchfONSZFRKQvcStJv/WlfBUJ8Xe35ia6ISIi0gu4laTf+lJ+0g7E2d1qjLnAGNM/6vYAY8z5CWuViIgkh1tJtiokgfjHJH9kra1vv2GtrQN+lJAWiYhI8riVZKv1keFN7YUEIP6Q7G6/eE8fERGRI0V7SEa8qiSJPySXGWN+a4wZ5/78FlieyIaJiEgSuCHZEvFq4g7xh+TNQBvwN+BJwA98LVGNEhGRJAm2AtAc0ZgkxD+7tRm4PcFtERGRZHMryaawL+VX24H4Z7e+YowZEHU73xjzcsJaJSIiydFeSWp2KxB/d2uRO6MVAGttLXGsuGOMOdsYs8EYU2qM2acSNcb8zhiz0v3ZaIyp6+ZpRETkcOmoJL2qJIl/hmrEGDPSWrsdwBgzmm6uChLNGOMB7gXOAsqB940xz1lrS9r3sdZ+I2r/m4HpB9d8ERHpUUEnJBtCPgYpJOMOyTuAN40x/wEM8Ang+gM85gSg1Fq7GcAY8yQwDyiJsf+l6NxLEZHkCrZAmhd/2Og8SeLsbrXWvgTMAjYATwDfBFoP8LBhQFnU7XJ32z6MMaOAMcCiGPdfb4xZZoxZtmfPnniaLCIihyLkB28WbaGITgEh/gXOrwVuBYYDK4E5wNvAGT3UjkuAZ6y14e7utNYuABYAzJo1a7/dvCIi8jEEW8GXSZs/ook7xD9x51bgeGCbtfZ0nLHDugM8ZgcwIur2cHdbdy7BqVBFRCSZQn7wuZWkQjLukPRba/0AxpgMa+164KgDPOZ9YIIxZowxJh0nCJ/rupMxZhKQj1OZiohIMgVbwZtFIBRWSBL/xJ1y9zzJfwCvGGNqgW37e4C1NmSMuQl4GfAAD1pr1xpjfgwss9a2B+YlwJPWWnWjiogkW8iP9WUSDFudAkL8K+5c4P56pzFmMdAfeCmOx70IvNhl2w+73L4zrpaKiEjiBVuxnkwAVZIcwpU8rLX/SURDRESkFwi2EvFmAWh2K/GPSYqISCoItRJOcypJdbcqJEVEJFrQT9jbHpJaTEAhKSIie4X8hNMyAI1JgkJSRESiBVsJpWniTjsdARER2SvkJ9ReSWrijkJSRERc1kKwhWBaOqBKEhSSIiLSLhwEGyFonEpSs1sVkiIi0i7kXNypTWOSHXQERETE4V5wuc2ou7WdjoCIiDjaK0nU3dpOR0BERBxuJRlwK0ktJqCQFBGRdsEWAAJW3a3tdARERMQRcipJPz5A50mCQlJERNoFnTHJVlWSHXQERETE4VaSrbSPSSoidARERMThVpJ+m06aAa+6WxWSIiLicivJFutTV6tLR0FERBxuJdkS8WnSjktHQUREHG5INkXSSdc5koBCUkRE2rV3t0a8mrTj0lEQERFHsBXSfPgjaQpJl46CiIg4Qn7wZdEWCmvijktHQUREHMFW8GYSCEUUki4dBRERcYT84MukLRRRd6tLR0FERBzBFvBm0aZKsoOOgoiIOIJuJRmO6DxJl46CiIg4Qq2qJLvQURAREUfQmd3qTNzRYgKgkBQRkXahVvcUEE3caaejICIijqBfp4B0oaMgIiKOYOvexQQ0cQdQSIqISLvQ3sUE1N3q0FEQERFH0I/1OqeAKCQdOgoiIgLWQqiViDcLa9GYpEtHQUREIBwEGyHsyQAUku10FERExBmPBIJpmQCauOPSURAREef0DyBknEoyw6fFBEAhKSIi4CxuDoTS3O5WVZKAQlJERMC5TBYQTEsHNCbZTkdBRESchQSAgFFIRtNREBGRjkqyzbgTdxSSgEJSRERgbyWJU0lqMQGHjoKIiHRUkgrJznQURESko5JstT4AMnQ9SUAhKSIi0BGSjWEnJHMzvclsTa+hkBQRkY7u1oagU0HmZCgkQSEpIiLQUUnWu5VkjipJQCEpIiLQUUnWtnlI96ZpTNKlkBQREaeSTPPREIiQq67WDgpJERFxQtKXRVMgpEk7URSSIiLiXCrLm0mjP6TxyCgKSRERcS6V5cukyR8iN8OX7Nb0GgpJERFxK8ksGvxBVZJRFJIiIuJWkhqT7EohKSIiTiXZHpKa3dpBISkiIhBsxboTd3IzNSbZTiEpIiIQ9BPxZBKOWI1JRlFIiogIhFoJpjmXydK6rXspJEVEBIJ+2kwGoCuARFNIiogIhFoJKCT3oZAUEREI+gngdLdq4s5eCkkRkVRnLYRa8VuNSXalkBQRSXXhNrARWq1TQaq7dS+FpIhIqnMvuNwScUNSa7d2UEiKiKQ694LLzW5I9svQBZfbKSRFRFKdW0k2Rbxkp3vwehQN7XQkRERSnVtJNobTNWmnC4WkiEiqcyvJhpBXk3a6UEiKiKQ6NyTrQx5ydI5kJwpJEZFUF3JDMughT5VkJwpJEZFUF3TGJOuCHo1JdqGQFBFJde7EndqAQrIrhaSISKpzxySr27xat7ULhaSISKpzK8matjRdcLkLhaSISKoLtgDQatM1caeLhIakMeZsY8wGY0ypMeb2GPt8wRhTYoxZa4x5PJHtERGRbrgTd/xoMYGuEnY0jDEe4F7gLKAceN8Y85y1tiRqnwnA94C51tpaY8ygRLVHRERiCLVi03xESNOYZBeJrCRPAEqttZuttW3Ak8C8LvtcB9xrra0FsNbuTmB7RESkO0E/EU8mgMYku0hkSA4DyqJul7vbok0EJhpj3jLGvGOMOTuB7RERke6EWgl7MgBdS7KrZB8NLzABOA0YDiwxxkyx1tZF72SMuR64HmDkyJGHuYkiIn1c0E8wzakkczUm2UkiK8kdwIio28PdbdHKgeestUFr7RZgI05odmKtXWCtnWWtnTVw4MCENVhEJCWFWgmlOZWkuls7S2RIvg9MMMaMMcakA5cAz3XZ5x84VSTGmCKc7tfNCWyTiIh0FWylzaQDaOJOFwkLSWttCLgJeBlYBzxlrV1rjPmxMeY8d7eXgWpjTAmwGPi2tbY6UW0SEZFuBFsJkI4xkO3zJLs1vUpC62pr7YvAi122/TDqdwvc5v6IiEgyhPwE3HMk09JMslvTq2jFHRGRVBf04yddk3a6oZAUEUl1oVZabLrGI7uhkBQRSXVBPy2RdM1s7YaOiIhIqgu20Gy9Wre1GzoiIiKpLuSnCZ9W2+mGjoiISCqzFoKtNKZ5FZLd0JikiEgqa2sCLHUhTdzpjkJSRCSVVX8EwKbQII1JdkMhKSKSyqpLAfjIDlV3azcUkiIiqaxqI9aksc0Wq5LshkJSRCSVVW0imDOcNs1u7ZZCUkQklVVvoiVvHKArgHRHISkikqoiEagqpaHfKAB1t3ZDISkikqoadkColZosJyTV3bovhaSISKqq3gRAZYZbSSok96GQFBFJVVVOSFZ4hgOQpzHJfSgkRURSVdUmyMhjj83Dm2bI8CoSutIRERFJVdWboGgCjYEwOZlejDHJblGvo5AUEUlVVZugcAJN/pAm7cSgkBQRSUVtzc7s1qLxNPhD5GRoPLI7CkkRkVTkrtlK0USaAkFVkjEoJEVEUpE7s5XCCTT6Q+RqIYFuKSRFRFJR1SbAQMFYmgIak4xFISkikoqqN0H+KPBl0uQPaSGBGBSSIiKpqGojFE4AcLpbtZBAtxSSIiKpJhKB6o+gaAIN/iBt4QgDshSS3VFIioikmsadEGyBogls2NUIwMTi3CQ3qndSSIqIpJqoma3rKhoAOHpIXhIb1HspJEVEUk17SBY5IZmf7aM4LyO5beqlFJIiIqmm2lnYnJxiSioaOXpIntZtjUEhKSKSaqo2QeF4whY27Gpg0mB1tcaikBQRSTXVH0HheLZWN+MPRjh6iCbtxKKQFBFJJUE/1JdB4ThN2omDQlJEJJXUbgEsFI5nXUUD3jTDhOKcZLeq11JIioikkuqPnH8LxrKuopFxA3PI8HqS26ZeTCEpIpJKatyQdLtbNR65fwpJEZFUUl0K/QZSF8miot6v8cgDUEiKiKSS6s1QMI51Fc5ydArJ/VNIioikkpqPNLP1ICgkRURSRaAJGivcSTsNFOVkMDBXy9Htj0JSRCRV1Gx2/i0cz7pdmrQTD4WkiEiqcGe2hgaMYWNlE5PV1XpACkkRkVRRXQrAFjuYtlCESaokD0ghKSKSKqo3Q+5QSqpCgCbtxEMhKSKSKtyZrSUVDaR70hg3UMvRHYhCUkQkVVSXEikYy9LSasYPysHnUQQciI6QiEgqaK2DlmqW1vZnzY56rj55TLJbdERQSIqIpAJ3ZusjG72cf9xQLpoxLMkNOjIoJEVEUkDzzg0A+PPGcNcFUzDGJLlFRwaFpIhIH2etZdFbbxOxhm/P/xQ5Gd5kN+mIoZAUEenj/vrONsLVpTRnDWHK6MHJbs4RRSEpItKHlexs4K4X1jEtq4qcoUcluzlHHIWkiEgf1dIW4qYnPmBAppdRZhemcFyym3TEUUiKiPRRP/rnWrZUNfPHC0aSFmiAAoXkwVJIioj0Qf9cuYOnl5dz8+njOSG31tlYOD65jToCKSRFRPqYkp0N3LHwQ44fnc8tZ06Aqk3OHepuPWgKSRGRPmT9rgYue+AdcjO9/OGS6Xh3LoNXfgi5Q2DAyGQ374ijkBQR6SM2VjZy2Z/fJcPr4Ynr5jC04lV4+FzIGgBXvgAeX7KbeMRRSIqI9HLWWp5btZPbnlrJqyWVRCJ2n302VTbyxT+/gyfN8MT1cxj90aPwt8th8BS45hV1tR4iLbsgItKLrSqr48fPl7B8Wy0Z3jT+/sEOxhT146q5o5k8JI+3P6rmzdIqVmyvo3+2jyeun8OY3a/Bv74Dk86BC/8M6dnJfhtHLIWkiEgv8dSyMlaW1XXcrmoM8O+SSopyMvjlRVOZN30oL6+t5H/f3MIP/7m2Y79jhuZx5dzRfGn2KEb2C8LD33YqyIsfBo++5j8OHT0RkV7gj4s28et/b2RAtg9vmjMS5k0z3HDqOL52+jhyM53xxPOmDeW8aUNZsb2WygY/J4wppKBf+t4neuGb0LwbLn1cAdkDdARFRJLsT6+X8ut/b+TC6cP41cXT8KQd+Aod00fm77tx+7vw/v/CnBth2MwEtDT1aOKOiMhhVNngp74liLXO5Jv7//MRv3xpA/OOGxp3QHYr1Ab/dyvkDYPT7+jBFqc2VZIiIl1U1LfSHAgzflBOt/f7g2E+3FHPiu11fLC9Fn8wzPc+ezQTi3NjPmdLW4gf/XMtTy8vB8DnMRT0S6eyIcC504bym4MNyIadUL5s7+0tS2DPOrj0Scjovt1y8BSSItIn7W70s7POz7Th/eO+wHAkYnnk7a384iXnAsVP33Aixw7r32mft0qruP6RZTS3hQEYUZBFcyDMOfe8yfc+M4krThxNWpew21TZyFcf+4DSPU1ce/IYBvfPpKqpjaqmAEP6Z3LrmRPweuLs2LMWVj0JL34b2ho733fsRXDUZ+J7HomLQlJE+pRQOMIjb2/jN//eQHNbmCnD+vO108fzqcnF+4RXtC1VzXz3mdW8t7WGUyYO5KPdTVzz8Pv882snM7h/JgBryuu5/pFlDMvP4lufOorpI/MZmJvBnsYA3312Nf/9fyUsWr+bm04fTzBsaW4Lsa26md+9sol+GR7+evVsTp5QdOhvrqUGnv8GlPwDRs2FT/43+LKc+0waDJx06M8t3TLt/eJHilmzZtlly5YdeEeRXqK+JciDb20B4LpTxqbUVeGttXywvZbl22o5Z+pQhg7I+ljPV9vcRnNbiGEDsrqtDldsr+WOhR9SUtHAqRMHcubRg3jwzS1srW5hYnEOJ44tpKUtTEswTEsgREtbmNZgmJa2MNtrWsj0pvFf50zm8zOHs35XI5+/byljB+bw1FdOZFeDn8/ft5RMn4dnbzypIzij3+tj727nrhdK8Acjne47cWwhf7jkOAbldX5M3CIRKFkIL//Ambl6+h0w91ZI8xza80knxpjl1tpZ3d6nkEyeZ5eXs62mhZvPGI8v3q4WVzAcoWRnAyu217KirI51FQ3MGJnP1SeP2e+4yMGy1hKxHPpkgj6itS3Mvz6soLktzOdnDCcr/cBfTq1tYR5auoX/ef0jGvwhAIb0z+RH507m08cM3udL3lrL9poW3iqtZk9jgBPGFDBj1AAyvPt/rUjE7rdCAiiraeHJ97fzxqYqLpw+jC930yXYlT8YJsOb1m0YRSKW2pY2J3DawrS0hcjweijKSSffPR3hxTUVPPjmFlaV1wPOGNxFM4Zz42njGFXYj+3VLbxZWsXbm6upa2nreG5vmmHW6AI+NbmY8YNyMMZQsrOBB9/awnMrd9IWjlCUk8H0kQOYNrw/Df4Q63c1smFXA5UNAYrzMvjRucfwmWOdYxwKR3hhTQX/85/N7KhtoV+Gl6x0D9npHrJ9XrIznN8H5WZy42njKI4KstfWVXLtI8s446hBbNzdSHMgzNM3nMi4gbHH/HbUtbKpstF5HZ+HnAwvowqzD9zlGw4644rhIAw6eu86q6Wvwms/hl2rYdAxcP6fYOhx+38uOSgKyQTaXt1CdXOg++nY+7FhVyPn3PMGwbBl7vhC/vTFmfTPjm9dxY2Vjdzw1+VsrmoGoDgvg4nFuby3pYZAKMInJhRx9dwxnDyh6KDDN9rmPU3c/MQKjIG/XX8i/VKoAgIntNZVNPLk+9tZuGIHjW7QDcrN4JYzJzD/+BH4PGmEwhHW72pkzY56Khv8VDUFqG5qY9m2WvY0Bjhj0iC+9amj8IfC3LHwQ9ZVNHDGpEFRVU2I6qY23tlcTXlta6c2ZPrSOGFMIRfPHM45U4d0+qINhiP89IV1PP7udqYO789Zk4s5a3Ixowv7UdnoZ3t1C1urm3l+dQVvbKoizcDYgTmU7m7ihNEF/OLzUxlT1A+ARn+QdzfXsLq8zgmcyka217TQL93LxOIcjhqcx4iCLLZXt7B+VyObKhs7xuS6k+FNIxCKdKwMc9K4Qh55extPvl9GKBxhcF4mO+v9gPP5ja4wWwJhNlQ6Y22jC7MZmJvB+1tryfJ5+PzM4UwszmFFWR0rttexpaqZdG8a4wfmMGlwLscM688XZg3vOKewJzzwxmbuemEd2enOeqjTRgw49CezFvz1YKMqzaqNsOZpWLsQWqr3bk/PhZxBUPMRDBgFZ/zAGXNU9djjFJIJ8tKHu/jmUysJhi2LvnUqw/PjW/opHLFceN9Sympa+Nrp4/n5v9YxIj+bB66Yxdj9/IUKzl/n33p6FdnpXu743CRmjyns+IKpaW7j8Xe38cjb29jdGCAv08vpkwZx1uRiTjtq0EF18/1z5Q6+//c1eD1pNPqDnDW5mPsum3nA6uNQhcIRtla3UFbTwvaaFsprWzh6SB7nThvaKegDoTBPvLudtz6q5rgRAzh5fBHHDutPmoGKej8rttexekcdeZk+jirO5ajBuQzpn0npniY+2FbHiu21lNe2kpXucaoJn4ei3AxGFmQzIj+bwf0zWLuzgaWlzlJfO+paSfem8dljB3PJCSNJM4ZfvrSeZdtqGVWYTXFeJmvK62kN7g2M/GwfhTkZjC7M5iunjuP40QWd3udflm7ld69s7AiZdG8aeZleZozMZ+74IuaOL2Jgbgbvbq5m6UfVvL5hN1urW/jk0YP46QVTKM7LZHejn5seW8F7W2v47JTBbK1qoaSiAXAqtmB47//XwwZkMf/4EVw8aziD8zJ5Znk5P3m+hEAowoUzhrNhVwOryusJRyxpBkYX9WPS4FzGD8qlrqXNrdIaqW8Nkp/t46jBuUwanMfowmz6ZXjJTveSne4hEAqzp6mN6qYAdS1BPjGhiNOPGtTpM7O7wc8Db26hrKaFOWMLmTu+iHED++1TZe2q9/PqukpeKalkR10rF80YzqUnjGBAdnqn/Rr8QbJ9nvgnvRwCay2PvrudyUNymTmq4MAPaBdogt3rYPdaqCyB3SVQuRZaa/bd15vlTLiZ8nnILtr7mJrNzvYZV4A3fd/HSY9QSPawcMTy21c2cO/ij5gyrD8bKxv53JQh/Hb+cXE9vv0v07svnc5504by3pYavvLXZYQjlpPGFTmVSHMbjf4gE4tzmT5yANNH5LNsWy3/85+PmD5yAPddNnOfMZF2baEIizfs5pWSShat301NcxvZ6R4unjmcq+aOYbRbPYAzXlZS0UBbeO9fti99WMET75Uxa1Q+93xxOi+sruCuF9bxjU9O5NZPTtjve2sOhFhdXs8H22tZVVbHiIJsbjp9fEcXXLSmQIg3Nu5x2rlhN3UtwY77vGmGUMQyoiCLG08dzwXTh/HCmgp+98pGdtS1MqR/JhVuJZKX6XSfVTYEgH1DIs1A+3rQ+dk+xg7MIRAK0xJwugqrmwOd9m9/zhPHFXLyhIGcO3VIpy9nay2LN+zmj4tKCVuYMXIA00fmc9zwAQwZkBlX9e4PhmkLR+L6gg9HLA+9tYVfvbyBdG8aN5w6jkfe3kp9a5BfXDSVeccNA6C8toVXSyrZ1RBgREFWR/CPKMjep7u8ssHPHQs/ZPGG3UwZ1p+Txxdx0vhCZozMJ9O3b6ViraUpECInwxv3TNEjVnM1vPV7KHvvEJ/AQuMuqNu2d5Ovn9OFWjwZCieAN2PvfdmFMPHTkNFzwyRycBSSPagpEOKrj33Ako17uOT4Efz3vGP43SubuH/JR7xw8yeYPDSv075/XFTKrFH5nDHJ+Yt6e3ULn/r9fzh5fBF//vKsji+c7dUtfOuZVdQ2t1GYk05RTgZZPg/rdjWwrqKRsPstf9nskfzw3MkHHKdqF45Ylm+r5W/vl/Hcqh2EIpYzJw0iPzudFWV1lO5u6vZxXz1tHLedNRGvJw1rLd98ehV//2AH918+k09NLmZlWR1PvLedV0oqaQvtDdjWYLgjkEYVZlNW00JOhpevf3Iil584inDEsmj9bv65cgeLN+yhLRRhQLaPM44axNzxRYwucr7Ui/plsGj9bu5ZXMqqsjrSPWm0hSMcOyyPb396EqdMKKKqqY2lH1WxtLSaQCjMcSMGMGNUPpMG5xEIhdlY2cT6XQ2U17YysTiH6SPyux0bCkcsuxqc7smdda2MH5TDscP697px2OjZlyMLsrn/8pkcPSTvwA/cj3DE9rr3mTSBRnj7T7D0Hgg2w4g5h35pqewCZ/yweLI7vjga0rR2S2+lkOxBv31lI3e/tomfXTCFL852BtbrW4Kc8qvFHDdiAA9ffQLgVHNX/+V93iytApyxlavmjuHltbtYU17Pv287hSH945vp19oWZs2OeiLWMmds4SG3fXejn0ff2c5j72zDAtNHDGD6yAFMHT6g03hjQb/0jrGqdv5gmPn3v03p7iZGFGSzflcj2ekePn3MYAqjqsScTC/TRgzguOEDyO+XzoZdjdz1QglvbKpiREEWdc1BGgMhinIyOGfqEM4+djCzRuXHrKastbxZWsVzK3dy+qRBHZMxUlUkYvnPxj3MGJkf9xi2dNFQAWv/Dhv+5QRju7pt0FoLR58Lp/8ABul0ilShkOwhTYEQc3++iNljCljw5c7H889LNvPTF9fx+LWzmTO2kFv/tpL/W7WTn184hX4ZXv73zS0dq/tHB2wytP83P9iw2VXv5/P/s5T87HQuPWEk504bEtcECWud6vH+/2xmZGE25x83jBPHFaqCkZ4RDjljd7vXQvVHnSfFRLMR2PYWbHkDsFA8BfKG7r0/M09rnqYohWQPWbDkI3724nr+8bW5HNdlhps/GObM3/yHwpx0ZozM5y9Lt/Ldsydx42l7L3T6wfZa1lc0csnxIxI2AUbkiGYt7NngnO5QudaZ7NJcBUUT3a7LY8DQeSLMng0QDsT3/AXjYMrFzgSZov2Pr0vq2F9IJnROvzHmbOAPgAd4wFr78y73Xwn8CtjhbvqjtfaBRLbpUAVCYR54YwsnjSvcJyABMn0ebjtrIt98ehWry+u55uQx3HDq2E77zBiZz4yDPFVEJCVUlTqnQXz4DFSXOtvSfE445gx0zh9c/WTnx+QMdoJzzClQfAwMmuzsHz0ppiudPiEHKWEhaYzxAPcCZwHlwPvGmOestSVddv2btfamRLXjoEUi8PL3oPx9Z8DdHXx/vrw/uxsD/PYLx8V86PnTh/GPlTsYWZDNHZ89+vCNnQX9zhdLKM6/prsyBgrGQFaXAI9EoH67M9tPeq9gM+xev/e0gabK2PumeSB/zN6qrGAspLV/DVjnsZUlznPtXg/BlsS3PxKGhnLAwOiT4cSbYMRsp9KLnjjTUuOcUmEjTihmH8TpGCKHKJGV5AlAqbV2M4Ax5klgHtA1JJOjrRnS++27fckv4d3/gaHTYcNLsOJRAC4CzswaQP+l02DjRPDse0qDB/jrMPfGvxPWcpd1rgKwu8Qdh4l9Ynfccoc6X545g6Fqg/OF1Nb97FfphTIHOOExcg5On2Q3wm1QvQnefXP/XZT5o53KLOPjzZ6N2+ApcOyFnccIu8ougNFzD097RFyJDMlhQFnU7XJgdjf7XWSMOQXYCHzDWlvWzT49a9caePg8+NRP4LjLnEoKYN3/wev/DzvtUtrO+SMZPi807Wbp20t47fXFXDWhhQGBLbDmKafKSrZ+hU41MHmeU/WmH+J5VpGgU4lWupVIxWqn2+q4LzpflHlDifmlK8nn8cHAoyB3yN7P8oGEQ85KLnXbnXHAdtkFziLZutSSCJD8q4D8H/CEtTZgjPkK8DBwRtedjDHXA9cDjBzZA7NCs/Kdv7j/+TXY+BKcezc0VsDfv0J46Awu2TGfZT98mcF5mYwoyKasJp9+hV/gji+f4pyZLnKk83idYB14VLJbItKrJTIkdwAjom4PZ+8EHQCstdGDXQ8Av+zuiay1C4AF4Mxu/dgt6z8cvvwcvP1HZ+HgshPBk47NyOUHGbezfEsLV88dQ11LkLKaFrwew7c/fZRmpIqIpJhEhuT7wARjzBiccLwE+GL0DsaYIdbaCvfmecC6BLans7Q0mHsLjD0N/n4d1GzmmSn388Q7Ib7/2Ulcf8q4Az6FiIj0bQkLSWttyBhzE/AyzpyWB621a40xPwaWWWufA24xxpwHhIAa4MpEtSemIVPhK0tYsmoD33mmjPOPG8p1nxh74MeJiEifp8UEgE2VjVzwp6WMLsrmmRtO6naBZxER6Zv2t5hAyq+4u3lPE5c98C6ZPg8LLp+lgBQRkQ4pHZJbqpq59M/vEI5YnrhudqcLv4qIiCT7FJCk2VbdzKUL3iEYtjxx3RwmFOtabiIi0llKVpLbq1u4dME7BEJhHrt2NkcNVkCKiMi+UjIkA6Ew2RleHr129se+aK2IiPRdKdndOqE4l5e/foquZygiIvuVkpUkoIAUEZEDStmQFBERORCFpIiISAwKSRERkRgUkiIiIjEoJEVERGJQSIqIiMSgkBQREYlBISkiIhKDQlJERCQGhaSIiEgMCkkREZEYFJIiIiIxKCRFRERiUEiKiIjEoJAUERGJQSEpIiISg0JSREQkBmOtTXYbDooxZg+wrYeergio6qHn6st0nOKnYxUfHaf46VjF5+Mcp1HW2oHd3XHEhWRPMsYss9bOSnY7ejsdp/jpWMVHxyl+OlbxSdRxUneriIhIDApJERGRGFI9JBckuwFHCB2n+OlYxUfHKX46VvFJyHFK6TFJERGR/Un1SlJERCSmlAxJY8zZxpgNxphSY8ztyW5Pb2GMGWGMWWyMKTHGrDXG3OpuLzDGvGKM2eT+m5/stvYWxhiPMWaFMeZ59/YYY8y77mfrb8aY9GS3sTcwxgwwxjxjjFlvjFlnjDlRn6t9GWO+4f6/96Ex5gljTKY+Uw5jzIPGmN3GmA+jtnX7GTKOu91jttoYM+NQXzflQtIY4wHuBT4DTAYuNcZMTm6reo0Q8E1r7WRgDvA199jcDrxmrZ0AvObeFsetwLqo278AfmetHQ/UAtckpVW9zx+Al6y1k4BpOMdMn6soxphhwC3ALGvtsYAHuAR9ptr9BTi7y7ZYn6HPABPcn+uB+w71RVMuJIETgFJr7WZrbRvwJDAvyW3qFay1FdbaD9zfG3G+yIbhHJ+H3d0eBs5PSgN7GWPMcOBzwAPubQOcATzj7qJjBRhj+gOnAP8LYK1ts9bWoc9Vd7xAljHGC2QDFegzBYC1dglQ02VzrM/QPOAR63gHGGCMGXIor5uKITkMKIu6Xe5ukyjGmNHAdOBdoNhaW+HetQsoTla7epnfA98BIu7tQqDOWhtyb+uz5RgD7AEecrumHzDG9EOfq06stTuAXwPbccKxHliOPlP7E+sz1GPf86kYknIAxpgc4Fng69bahuj7rDMdOuWnRBtjzgF2W2uXJ7stRwAvMAO4z1o7HWimS9eqPlfgjqfNw/mjYijQj327FyWGRH2GUjEkdwAjom4Pd7cJYIzx4QTkY9bav7ubK9u7Ktx/dyerfb3IXOA8Y8xWnC77M3DG3Qa4XWWgz1a7cqDcWvuue/sZnNDU56qzTwJbrLV7rLVB4O84nzN9pmKL9Rnqse/5VAzJ94EJ7oyxdJyB8eeS3KZewR1T+19gnbX2t1F3PQdc4f5+BfDPw9223sZa+z1r7XBr7Wicz9Aia+1lwGLg8+5uOlaAtXYXUGaMOcrddCZQgj5XXW0H5hhjst3/F9uPkz5TscX6DD0HfNmd5ToHqI/qlj0oKbmYgDHmszjjSR7gQWvtT5Pbot7BGHMy8Aawhr3jbN/HGZd8ChiJcwWWL1hruw6gpyxjzGnAt6y15xhjxuJUlgXACuBL1tpAEpvXKxhjjsOZ4JQObAauwvkjXZ+rKMaY/wbm48w0XwFcizOWlvKfKWPME8BpOFf7qAR+BPyDbj5D7h8Zf8Tprm4BrrLWLjuk103FkBQREYlHKna3ioiIxEUhKSIiEoNCUkREJAaFpIiISAwKSRERkRgUkiK9kDEmbIxZGfXTY4t/G2NGR19JQURi8x54FxFJglZr7XHJboRIqlMlKXIEMcZsNcb80hizxhjznjFmvLt9tDFmkXvtvNeMMSPd7cXGmIXGmFXuz0nuU3mMMX92r134b2NMlrv/Lca5nuhqY8yTSXqbIr2GQlKkd8rq0t06P+q+emvtFJwVRX7vbrsHeNhaOxV4DLjb3X438B9r7TSc9VLXutsnAPdaa48B6oCL3O23A9Pd57khMW9N5MihFXdEeiFjTJO1Nqeb7VuBM6y1m93F6HdZawuNMVXAEGtt0N1eYa0tMsbsAYZHL2PmXgbtFfdCtRhjvgv4rLV3GWNeAppwlvv6h7W2KcFvVaRXUyUpcuSxMX4/GNFrf4bZOz/hc8C9OFXn+1FXnxBJSQpJkSPP/Kh/33Z/X4pzNRKAy3AWqgd4DbgRwBjjMcb0j/Wkxpg0YIS1djHwXaA/sE81K5JK9FeiSO+UZYxZGXX7JWtt+2kg+caY1TjV4KXutpuBh4wx3wb24FxlA+BWYIEx5hqcivFGnKved8cDPOoGqQHuttbW9dD7ETkiaUxS5AjijknOstZWJbstIqlA3a0iIiIxqJIUERGJQZWkiIhIDApJERGRGBSSIiIiMSgkRUREYlBIioiIxKCQFBERieH/AwfOcHdi80rmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.89670\n",
      "Test Precision: 0.39655\n",
      "Test Recall: 0.28049\n",
      "Test F1: 0.32857\n"
     ]
    }
   ],
   "source": [
    "model=GRU_model(embedding_layer)\n",
    "fit_=model.fit(x=X,y=Y,epochs=100,validation_split=0.2)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "chart(fit_,'accuracy')\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,2)\n",
    "chart(fit_,'loss')\n",
    "Y_preds=model.predict(X_test)\n",
    "Y_preds_label=np.round(Y_preds)\n",
    "Y_label=test_data.class_label.tolist()\n",
    "print(\"Test Accuracy: %.5f\" %accuracy_score(Y_label,Y_preds_label))\n",
    "print(\"Test Precision: %.5f\" %precision_score(Y_label,Y_preds_label)) \n",
    "print(\"Test Recall: %.5f\" %recall_score(Y_label,Y_preds_label)) \n",
    "print(\"Test F1: %.5f\" %f1_score(Y_label,Y_preds_label)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.9076923076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       828\n",
      "           1       0.48      0.24      0.32        82\n",
      "\n",
      "    accuracy                           0.91       910\n",
      "   macro avg       0.70      0.61      0.64       910\n",
      "weighted avg       0.89      0.91      0.89       910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopword=set(stopwords.words('english'))\n",
    "vectorizer=tfidf(stop_words=stopword,ngram_range=(1,2),max_features=500000)\n",
    "vectorizer.fit(train['tweet_text'])\n",
    "x_train=vectorizer.transform(train['tweet_text'])\n",
    "y_train=train['class_label']\n",
    "x_test=vectorizer.transform(test['tweet_text'])\n",
    "y_test=test['class_label']\n",
    "clf=LogisticRegressionCV()\n",
    "clf.fit(x_train,y_train)\n",
    "pred= clf.predict(x_test)\n",
    "print('accuracy=',accuracy_score(y_test,pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.90769\n",
      "Test Precision: 0.47619\n",
      "Test Recall: 0.24390\n",
      "Test F1: 0.32258\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy: %.5f\" %accuracy_score(y_test,pred))\n",
    "print(\"Test Precision: %.5f\" %precision_score(y_test,pred)) \n",
    "print(\"Test Recall: %.5f\" %recall_score(y_test,pred)) \n",
    "print(\"Test F1: %.5f\" %f1_score(y_test,pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/main/en/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2271: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [01:42<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.32740770642061706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:44<15:37, 104.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.49107029378927985\n",
      "f1 score: 0.5623536299765808\n",
      "Acc score: 0.8989010989010989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [03:23<15:37, 104.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.11045629180085446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [03:25<13:37, 102.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.5647968192913987\n",
      "f1 score: 0.6046457741991542\n",
      "Acc score: 0.9010989010989011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:03<13:37, 102.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.03868819420032913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [05:05<11:49, 101.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7369356509157585\n",
      "f1 score: 0.5492173223839194\n",
      "Acc score: 0.9010989010989011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [06:44<11:49, 101.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.020897770609994003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [06:46<10:06, 101.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.7817129868537825\n",
      "f1 score: 0.6106508875739645\n",
      "Acc score: 0.8967032967032967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [08:26<10:06, 101.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.014098671224246049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [08:27<08:26, 101.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 0.9850433229816001\n",
      "f1 score: 0.5650182238244139\n",
      "Acc score: 0.8945054945054945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [10:07<08:26, 101.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.0089204383796607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [10:09<06:45, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.0057936649898003\n",
      "f1 score: 0.6088805892727462\n",
      "Acc score: 0.9043956043956044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [11:47<06:45, 101.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.0035953404948066226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [11:49<05:02, 100.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.1274546078877454\n",
      "f1 score: 0.6019096165550822\n",
      "Acc score: 0.8989010989010989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [13:28<05:02, 100.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.008574459282377123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [13:29<03:21, 100.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.0298294377461514\n",
      "f1 score: 0.5839447102604998\n",
      "Acc score: 0.9054945054945055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [15:09<03:21, 100.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.0004946391810972203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [15:10<01:40, 100.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.091805511654143\n",
      "f1 score: 0.5752593462517127\n",
      "Acc score: 0.8978021978021978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [16:50<01:40, 100.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss:0.000862909733471728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:52<00:00, 101.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val loss: 1.1180490576499198\n",
      "f1 score: 0.5740803441614053\n",
      "Acc score: 0.8967032967032967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "encoded_data_train=tokenizer.batch_encode_plus(train.tweet_text.values,add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=60,return_tensors='pt')\n",
    "encoded_data_val=tokenizer.batch_encode_plus(test.tweet_text.values,add_special_tokens=True,return_attention_mask=True,pad_to_max_length=True,max_length=60, return_tensors='pt')\n",
    "input_ids_train=encoded_data_train['input_ids']\n",
    "attention_masks_train=encoded_data_train['attention_mask']\n",
    "labels_train=torch.tensor(train.class_label.values,dtype=torch.long)\n",
    "input_ids_val=encoded_data_val['input_ids']\n",
    "attention_masks_val=encoded_data_val['attention_mask']\n",
    "labels_val=torch.tensor(test.class_label.values,dtype=torch.long)\n",
    "dataset_train=TensorDataset(input_ids_train,attention_masks_train,labels_train)\n",
    "dataset_val=TensorDataset(input_ids_val,attention_masks_val,labels_val)\n",
    "\n",
    "model=BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2,output_attentions=False,output_hidden_states=False)\n",
    "dataloader_train=DataLoader(dataset_train,sampler=RandomSampler(dataset_train),batch_size=5)\n",
    "dataloader_val=DataLoader(dataset_val,sampler=RandomSampler(dataset_val),batch_size=32)\n",
    "optimizer = AdamW(model.parameters(),lr=1e-5,eps=1e-8)\n",
    "epochs=10\n",
    "scheduler=get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps=len(dataloader_train)*epochs)\n",
    "\n",
    "def f1_score_func(preds,labels):\n",
    "    preds_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return f1_score(labels_flat,preds_flat,average='macro')\n",
    "\n",
    "def accuracy_score_func(preds,labels):\n",
    "    preds_flat=np.argmax(preds,axis=1).flatten()\n",
    "    labels_flat=labels.flatten()\n",
    "    return accuracy_score(labels_flat,preds_flat)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    model.eval()\n",
    "    loss_val_total=0\n",
    "    predictions,true_vals=[],[]\n",
    "    for batch in dataloader_val:\n",
    "        batch=tuple(b.to(device) for b in batch)\n",
    "        inputs={'input_ids':batch[0],'attention_mask': batch[1],'labels':batch[2]}\n",
    "        with torch.no_grad():        \n",
    "            outputs=model(**inputs)\n",
    "        loss=outputs[0]\n",
    "        logits=outputs[1]\n",
    "        loss_val_total+=loss.item()\n",
    "        logits=logits.detach().cpu().numpy()\n",
    "        label_ids=inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    loss_val_avg=loss_val_total/len(dataloader_val) \n",
    "    predictions=np.concatenate(predictions,axis=0)\n",
    "    true_vals=np.concatenate(true_vals,axis=0)\n",
    "    return loss_val_avg,predictions,true_vals\n",
    "\n",
    "seed_val=200\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total=0\n",
    "    progress_bar=tqdm(dataloader_train,desc='Epoch {:1d}'.format(epoch),leave=False,disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch=tuple(b.to(device) for b in batch)\n",
    "        inputs={'input_ids':batch[0],'attention_mask':batch[1],'labels':batch[2]}\n",
    "        outputs=model(**inputs)\n",
    "        loss=outputs[0]\n",
    "        loss_train_total+=loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch))})\n",
    "    torch.save(model.state_dict(),f'BERT_ft_epoch{epoch}.model')\n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    loss_train_avg=loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss:{loss_train_avg}')\n",
    "    val_loss,predictions,true_vals=evaluate(dataloader_val)\n",
    "    val_f1=f1_score_func(predictions,true_vals)\n",
    "    val_acc=accuracy_score_func(predictions,true_vals)\n",
    "    tqdm.write(f'Val loss: {val_loss}')\n",
    "    tqdm.write(f'f1 score: {val_f1}')\n",
    "    tqdm.write(f'Acc score: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.89670\n",
      "Test Precision: 0.33333\n",
      "Test Recall: 0.14634\n",
      "Test F1: 0.20339\n"
     ]
    }
   ],
   "source": [
    "predictions=np.argmax(predictions,axis=1).flatten()\n",
    "true_vals=true_vals.flatten()\n",
    "print(\"Test Accuracy: %.5f\" %accuracy_score(true_vals,predictions))\n",
    "print(\"Test Precision: %.5f\" %precision_score(true_vals,predictions)) \n",
    "print(\"Test Recall: %.5f\" %recall_score(true_vals,predictions)) \n",
    "print(\"Test F1: %.5f\" %f1_score(true_vals,predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 0.6472527472527473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.67      0.78       828\n",
      "           1       0.11      0.39      0.17        82\n",
      "\n",
      "    accuracy                           0.65       910\n",
      "   macro avg       0.51      0.53      0.47       910\n",
      "weighted avg       0.84      0.65      0.72       910\n",
      "\n",
      "Test Accuracy: 0.64725\n",
      "Test Precision: 0.10561\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.16623\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "train[\"sentiment_score\"]=train[\"tweet_text\"].apply(lambda x:TextBlob(str(x)).sentiment.polarity)\n",
    "train[\"sentiment\"]=np.select([train[\"sentiment_score\"]<0,train[\"sentiment_score\"]==0,train[\"sentiment_score\"]>0],['neg','neu','pos'])\n",
    "test[\"sentiment_score\"]=test[\"tweet_text\"].apply(lambda x:TextBlob(str(x)).sentiment.polarity)\n",
    "test[\"sentiment\"]=np.select([test[\"sentiment_score\"]<0,test[\"sentiment_score\"]==0,test[\"sentiment_score\"]>0],['neg','neu','pos'])\n",
    "vocab_list=dict(vocab_list)\n",
    "def get_key(d,val):\n",
    "    for key, value in d.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "\n",
    "X_emb=[]\n",
    "for i in range(len(X)):\n",
    "    emb=[]\n",
    "    for j in X[i]:\n",
    "        if j!=0:\n",
    "            emb.extend(vocab_list[get_key(word2idx,j)])\n",
    "        else:\n",
    "            emb.extend(np.repeat(np.array(0),500))\n",
    "    X_emb.append(emb)\n",
    "X_emb=pd.DataFrame(X_emb)\n",
    "\n",
    "X_test_emb=[]\n",
    "for i in range(len(X_test)):\n",
    "    emb=[]\n",
    "    for j in X_test[i]:\n",
    "        if j!=0:\n",
    "            emb.extend(vocab_list[get_key(word2idx,j)])\n",
    "        else:\n",
    "            emb.extend(np.repeat(np.array(0),500))\n",
    "    X_test_emb.append(emb)\n",
    "X_test_emb=pd.DataFrame(X_test_emb)\n",
    "\n",
    "x_train_sen=X_emb.merge(train[\"sentiment\"],how='outer',left_index=True,right_index=True)\n",
    "x_test_sen=X_test_emb.merge(test[\"sentiment\"],how='outer',left_index=True,right_index=True)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "x_train_sen[\"sentiment\"]=label_encoder.fit_transform(x_train_sen[\"sentiment\"])\n",
    "x_test_sen[\"sentiment\"]=label_encoder.fit_transform(x_test_sen[\"sentiment\"])\n",
    "\n",
    "clf=LogisticRegressionCV()\n",
    "clf.fit(x_train_sen,y_train)\n",
    "pred= clf.predict(x_test_sen)\n",
    "print('accuracy=',accuracy_score(y_test,pred))\n",
    "print(classification_report(y_test, pred))\n",
    "print(\"Test Accuracy: %.5f\" %accuracy_score(y_test,pred))\n",
    "print(\"Test Precision: %.5f\" %precision_score(y_test,pred)) \n",
    "print(\"Test Recall: %.5f\" %recall_score(y_test,pred)) \n",
    "print(\"Test F1: %.5f\" %f1_score(y_test,pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\tf_geometric\\layers\\conv\\gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
      "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n",
      "c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\tf_geometric\\layers\\conv\\gcn.py:79: DeprecationWarning: 'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\n",
      "  warnings.warn(\"'GCN.cache_normed_edge(graph, override)' is deprecated, use 'GCN.build_cache_for_graph(graph, override)' instead\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Shape: x => (20181, 500)\tedge_index => (2, 485068)\ty => None\n",
      "Graph Shape: x => (26692, 500)\tedge_index => (2, 743868)\ty => None\n",
      "Graph Shape: x => (21091, 500)\tedge_index => (2, 516596)\ty => None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]c:\\Users\\Ying Jhu\\anaconda3\\envs\\env_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 3/1000 [00:03<15:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0\tloss = 0.6921458840370178\ttest_accuracy = 0.9098901152610779\n",
      "Test Accuracy: 0.90989\n",
      "Test Precision: 0.00000\n",
      "Test Recall: 0.00000\n",
      "Test F1: 0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 27/1000 [00:03<00:54, 17.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 10\tloss = 0.5750411748886108\ttest_accuracy = 0.3032967150211334\n",
      "Test Accuracy: 0.30330\n",
      "Test Precision: 0.09412\n",
      "Test Recall: 0.78049\n",
      "Test F1: 0.16798\n",
      "step = 20\tloss = 0.4630354344844818\ttest_accuracy = 0.33076924085617065\n",
      "Test Accuracy: 0.33077\n",
      "Test Precision: 0.09524\n",
      "Test Recall: 0.75610\n",
      "Test F1: 0.16917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1000 [00:03<00:26, 35.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 30\tloss = 0.34896788001060486\ttest_accuracy = 0.3340659439563751\n",
      "Test Accuracy: 0.33407\n",
      "Test Precision: 0.09190\n",
      "Test Recall: 0.71951\n",
      "Test F1: 0.16298\n",
      "step = 40\tloss = 0.27917876839637756\ttest_accuracy = 0.4208791255950928\n",
      "Test Accuracy: 0.42088\n",
      "Test Precision: 0.10619\n",
      "Test Recall: 0.73171\n",
      "Test F1: 0.18547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 63/1000 [00:04<00:17, 53.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 50\tloss = 0.23374015092849731\ttest_accuracy = 0.6274725198745728\n",
      "Test Accuracy: 0.62747\n",
      "Test Precision: 0.13598\n",
      "Test Recall: 0.58537\n",
      "Test F1: 0.22069\n",
      "step = 60\tloss = 0.20112842321395874\ttest_accuracy = 0.6582417488098145\n",
      "Test Accuracy: 0.65824\n",
      "Test Precision: 0.14330\n",
      "Test Recall: 0.56098\n",
      "Test F1: 0.22829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 81/1000 [00:04<00:13, 67.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 70\tloss = 0.17314721643924713\ttest_accuracy = 0.7296703457832336\n",
      "Test Accuracy: 0.72967\n",
      "Test Precision: 0.17460\n",
      "Test Recall: 0.53659\n",
      "Test F1: 0.26347\n",
      "step = 80\tloss = 0.15478506684303284\ttest_accuracy = 0.692307710647583\n",
      "Test Accuracy: 0.69231\n",
      "Test Precision: 0.15625\n",
      "Test Recall: 0.54878\n",
      "Test F1: 0.24324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [00:04<00:11, 78.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 90\tloss = 0.13623937964439392\ttest_accuracy = 0.7296703457832336\n",
      "Test Accuracy: 0.72967\n",
      "Test Precision: 0.16667\n",
      "Test Recall: 0.50000\n",
      "Test F1: 0.25000\n",
      "step = 100\tloss = 0.13143087923526764\ttest_accuracy = 0.7263736128807068\n",
      "Test Accuracy: 0.72637\n",
      "Test Precision: 0.16466\n",
      "Test Recall: 0.50000\n",
      "Test F1: 0.24773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 121/1000 [00:04<00:10, 84.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 110\tloss = 0.1138099655508995\ttest_accuracy = 0.708791196346283\n",
      "Test Accuracy: 0.70879\n",
      "Test Precision: 0.15985\n",
      "Test Recall: 0.52439\n",
      "Test F1: 0.24501\n",
      "step = 120\tloss = 0.10620272904634476\ttest_accuracy = 0.7571428418159485\n",
      "Test Accuracy: 0.75714\n",
      "Test Precision: 0.18265\n",
      "Test Recall: 0.48780\n",
      "Test F1: 0.26578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 141/1000 [00:05<00:09, 86.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 130\tloss = 0.08955313265323639\ttest_accuracy = 0.7153846025466919\n",
      "Test Accuracy: 0.71538\n",
      "Test Precision: 0.16350\n",
      "Test Recall: 0.52439\n",
      "Test F1: 0.24928\n",
      "step = 140\tloss = 0.08857043832540512\ttest_accuracy = 0.7879120707511902\n",
      "Test Accuracy: 0.78791\n",
      "Test Precision: 0.19672\n",
      "Test Recall: 0.43902\n",
      "Test F1: 0.27170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 161/1000 [00:05<00:09, 88.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 150\tloss = 0.08045137673616409\ttest_accuracy = 0.7813186645507812\n",
      "Test Accuracy: 0.78132\n",
      "Test Precision: 0.19048\n",
      "Test Recall: 0.43902\n",
      "Test F1: 0.26568\n",
      "step = 160\tloss = 0.07512573152780533\ttest_accuracy = 0.7604395747184753\n",
      "Test Accuracy: 0.76044\n",
      "Test Precision: 0.17925\n",
      "Test Recall: 0.46341\n",
      "Test F1: 0.25850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 181/1000 [00:05<00:09, 88.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 170\tloss = 0.07120911031961441\ttest_accuracy = 0.7626373767852783\n",
      "Test Accuracy: 0.76264\n",
      "Test Precision: 0.18095\n",
      "Test Recall: 0.46341\n",
      "Test F1: 0.26027\n",
      "step = 180\tloss = 0.07024487853050232\ttest_accuracy = 0.7615384459495544\n",
      "Test Accuracy: 0.76154\n",
      "Test Precision: 0.18310\n",
      "Test Recall: 0.47561\n",
      "Test F1: 0.26441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 201/1000 [00:05<00:08, 88.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 190\tloss = 0.057819049805402756\ttest_accuracy = 0.7395604252815247\n",
      "Test Accuracy: 0.73956\n",
      "Test Precision: 0.16738\n",
      "Test Recall: 0.47561\n",
      "Test F1: 0.24762\n",
      "step = 200\tloss = 0.061194710433483124\ttest_accuracy = 0.7648351788520813\n",
      "Test Accuracy: 0.76484\n",
      "Test Precision: 0.17961\n",
      "Test Recall: 0.45122\n",
      "Test F1: 0.25694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 221/1000 [00:05<00:08, 89.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 210\tloss = 0.051441773772239685\ttest_accuracy = 0.7648351788520813\n",
      "Test Accuracy: 0.76484\n",
      "Test Precision: 0.18269\n",
      "Test Recall: 0.46341\n",
      "Test F1: 0.26207\n",
      "step = 220\tloss = 0.05982377007603645\ttest_accuracy = 0.7571428418159485\n",
      "Test Accuracy: 0.75714\n",
      "Test Precision: 0.18265\n",
      "Test Recall: 0.48780\n",
      "Test F1: 0.26578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 241/1000 [00:06<00:08, 89.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 230\tloss = 0.04634536802768707\ttest_accuracy = 0.7857142686843872\n",
      "Test Accuracy: 0.78571\n",
      "Test Precision: 0.19126\n",
      "Test Recall: 0.42683\n",
      "Test F1: 0.26415\n",
      "step = 240\tloss = 0.04558107629418373\ttest_accuracy = 0.791208803653717\n",
      "Test Accuracy: 0.79121\n",
      "Test Precision: 0.19318\n",
      "Test Recall: 0.41463\n",
      "Test F1: 0.26357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 261/1000 [00:06<00:08, 89.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 250\tloss = 0.04264986142516136\ttest_accuracy = 0.7989010810852051\n",
      "Test Accuracy: 0.79890\n",
      "Test Precision: 0.19018\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.25306\n",
      "step = 260\tloss = 0.04212963208556175\ttest_accuracy = 0.807692289352417\n",
      "Test Accuracy: 0.80769\n",
      "Test Precision: 0.20382\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.26778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 281/1000 [00:06<00:08, 89.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 270\tloss = 0.03950118646025658\ttest_accuracy = 0.7846153974533081\n",
      "Test Accuracy: 0.78462\n",
      "Test Precision: 0.17978\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.24615\n",
      "step = 280\tloss = 0.035412222146987915\ttest_accuracy = 0.7923076748847961\n",
      "Test Accuracy: 0.79231\n",
      "Test Precision: 0.18713\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.25296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 301/1000 [00:06<00:07, 89.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 290\tloss = 0.04620799049735069\ttest_accuracy = 0.80989009141922\n",
      "Test Accuracy: 0.80989\n",
      "Test Precision: 0.19868\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25751\n",
      "step = 300\tloss = 0.03931599482893944\ttest_accuracy = 0.803296685218811\n",
      "Test Accuracy: 0.80330\n",
      "Test Precision: 0.19108\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 321/1000 [00:07<00:07, 89.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 310\tloss = 0.03421838954091072\ttest_accuracy = 0.7604395747184753\n",
      "Test Accuracy: 0.76044\n",
      "Test Precision: 0.17619\n",
      "Test Recall: 0.45122\n",
      "Test F1: 0.25342\n",
      "step = 320\tloss = 0.03250943869352341\ttest_accuracy = 0.7494505643844604\n",
      "Test Accuracy: 0.74945\n",
      "Test Precision: 0.17411\n",
      "Test Recall: 0.47561\n",
      "Test F1: 0.25490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 341/1000 [00:07<00:07, 89.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 330\tloss = 0.03269683197140694\ttest_accuracy = 0.7483516335487366\n",
      "Test Accuracy: 0.74835\n",
      "Test Precision: 0.17040\n",
      "Test Recall: 0.46341\n",
      "Test F1: 0.24918\n",
      "step = 340\tloss = 0.037387650460004807\ttest_accuracy = 0.805494487285614\n",
      "Test Accuracy: 0.80549\n",
      "Test Precision: 0.19745\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.25941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 361/1000 [00:07<00:07, 89.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 350\tloss = 0.02714417688548565\ttest_accuracy = 0.8065934181213379\n",
      "Test Accuracy: 0.80659\n",
      "Test Precision: 0.19872\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26050\n",
      "step = 360\tloss = 0.027199096977710724\ttest_accuracy = 0.7824175953865051\n",
      "Test Accuracy: 0.78242\n",
      "Test Precision: 0.19474\n",
      "Test Recall: 0.45122\n",
      "Test F1: 0.27206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 381/1000 [00:07<00:06, 89.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 370\tloss = 0.022534243762493134\ttest_accuracy = 0.7824175953865051\n",
      "Test Accuracy: 0.78242\n",
      "Test Precision: 0.19149\n",
      "Test Recall: 0.43902\n",
      "Test F1: 0.26667\n",
      "step = 380\tloss = 0.02973249740898609\ttest_accuracy = 0.8109890222549438\n",
      "Test Accuracy: 0.81099\n",
      "Test Precision: 0.20779\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.27119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 401/1000 [00:07<00:06, 89.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 390\tloss = 0.02477419376373291\ttest_accuracy = 0.7791208624839783\n",
      "Test Accuracy: 0.77912\n",
      "Test Precision: 0.18519\n",
      "Test Recall: 0.42683\n",
      "Test F1: 0.25830\n",
      "step = 400\tloss = 0.024596771225333214\ttest_accuracy = 0.8153846263885498\n",
      "Test Accuracy: 0.81538\n",
      "Test Precision: 0.20946\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 421/1000 [00:08<00:06, 89.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 410\tloss = 0.025926513597369194\ttest_accuracy = 0.7769230604171753\n",
      "Test Accuracy: 0.77692\n",
      "Test Precision: 0.17297\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.23970\n",
      "step = 420\tloss = 0.02082178182899952\ttest_accuracy = 0.7989010810852051\n",
      "Test Accuracy: 0.79890\n",
      "Test Precision: 0.18634\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 441/1000 [00:08<00:06, 89.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 430\tloss = 0.02239394001662731\ttest_accuracy = 0.7890110015869141\n",
      "Test Accuracy: 0.78901\n",
      "Test Precision: 0.18750\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.25581\n",
      "step = 440\tloss = 0.019177507609128952\ttest_accuracy = 0.79340660572052\n",
      "Test Accuracy: 0.79341\n",
      "Test Precision: 0.18072\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 461/1000 [00:08<00:06, 89.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 450\tloss = 0.019423561170697212\ttest_accuracy = 0.803296685218811\n",
      "Test Accuracy: 0.80330\n",
      "Test Precision: 0.19497\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.25726\n",
      "step = 460\tloss = 0.02377856895327568\ttest_accuracy = 0.7824175953865051\n",
      "Test Accuracy: 0.78242\n",
      "Test Precision: 0.18478\n",
      "Test Recall: 0.41463\n",
      "Test F1: 0.25564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 481/1000 [00:08<00:05, 89.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 470\tloss = 0.026196928694844246\ttest_accuracy = 0.7835164666175842\n",
      "Test Accuracy: 0.78352\n",
      "Test Precision: 0.17877\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.24521\n",
      "step = 480\tloss = 0.02243088372051716\ttest_accuracy = 0.812087893486023\n",
      "Test Accuracy: 0.81209\n",
      "Test Precision: 0.20530\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 501/1000 [00:09<00:05, 89.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 490\tloss = 0.0209891926497221\ttest_accuracy = 0.7516483664512634\n",
      "Test Accuracy: 0.75165\n",
      "Test Precision: 0.16972\n",
      "Test Recall: 0.45122\n",
      "Test F1: 0.24667\n",
      "step = 500\tloss = 0.018103202804923058\ttest_accuracy = 0.795604407787323\n",
      "Test Accuracy: 0.79560\n",
      "Test Precision: 0.18675\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 521/1000 [00:09<00:05, 89.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 510\tloss = 0.019208937883377075\ttest_accuracy = 0.7824175953865051\n",
      "Test Accuracy: 0.78242\n",
      "Test Precision: 0.17778\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.24427\n",
      "step = 520\tloss = 0.021295607089996338\ttest_accuracy = 0.7989010810852051\n",
      "Test Accuracy: 0.79890\n",
      "Test Precision: 0.19394\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.25911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 541/1000 [00:09<00:05, 89.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 530\tloss = 0.014936068095266819\ttest_accuracy = 0.7923076748847961\n",
      "Test Accuracy: 0.79231\n",
      "Test Precision: 0.18713\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.25296\n",
      "step = 540\tloss = 0.01898135431110859\ttest_accuracy = 0.791208803653717\n",
      "Test Accuracy: 0.79121\n",
      "Test Precision: 0.18605\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.25197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 561/1000 [00:09<00:04, 89.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 550\tloss = 0.022251663729548454\ttest_accuracy = 0.8065934181213379\n",
      "Test Accuracy: 0.80659\n",
      "Test Precision: 0.19481\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25424\n",
      "step = 560\tloss = 0.015207313001155853\ttest_accuracy = 0.807692289352417\n",
      "Test Accuracy: 0.80769\n",
      "Test Precision: 0.19608\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 581/1000 [00:09<00:04, 88.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 570\tloss = 0.019508717581629753\ttest_accuracy = 0.7725274562835693\n",
      "Test Accuracy: 0.77253\n",
      "Test Precision: 0.18274\n",
      "Test Recall: 0.43902\n",
      "Test F1: 0.25806\n",
      "step = 580\tloss = 0.018580006435513496\ttest_accuracy = 0.8274725079536438\n",
      "Test Accuracy: 0.82747\n",
      "Test Precision: 0.21374\n",
      "Test Recall: 0.34146\n",
      "Test F1: 0.26291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 601/1000 [00:10<00:04, 88.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 590\tloss = 0.02308519184589386\ttest_accuracy = 0.7780219912528992\n",
      "Test Accuracy: 0.77802\n",
      "Test Precision: 0.18421\n",
      "Test Recall: 0.42683\n",
      "Test F1: 0.25735\n",
      "step = 600\tloss = 0.019622184336185455\ttest_accuracy = 0.8175824284553528\n",
      "Test Accuracy: 0.81758\n",
      "Test Precision: 0.20833\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.26549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 621/1000 [00:10<00:04, 88.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 610\tloss = 0.021250272169709206\ttest_accuracy = 0.7835164666175842\n",
      "Test Accuracy: 0.78352\n",
      "Test Precision: 0.17877\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.24521\n",
      "step = 620\tloss = 0.013249796815216541\ttest_accuracy = 0.8197802305221558\n",
      "Test Accuracy: 0.81978\n",
      "Test Precision: 0.21127\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.26786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 641/1000 [00:10<00:04, 88.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 630\tloss = 0.031033899635076523\ttest_accuracy = 0.8021978139877319\n",
      "Test Accuracy: 0.80220\n",
      "Test Precision: 0.19753\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.26230\n",
      "step = 640\tloss = 0.014529521577060223\ttest_accuracy = 0.7769230604171753\n",
      "Test Accuracy: 0.77692\n",
      "Test Precision: 0.17989\n",
      "Test Recall: 0.41463\n",
      "Test F1: 0.25092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 661/1000 [00:10<00:03, 88.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 650\tloss = 0.012278980575501919\ttest_accuracy = 0.8219780325889587\n",
      "Test Accuracy: 0.82198\n",
      "Test Precision: 0.21014\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.26364\n",
      "step = 660\tloss = 0.014784426428377628\ttest_accuracy = 0.7835164666175842\n",
      "Test Accuracy: 0.78352\n",
      "Test Precision: 0.17877\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.24521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 681/1000 [00:11<00:03, 88.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 670\tloss = 0.01153829786926508\ttest_accuracy = 0.800000011920929\n",
      "Test Accuracy: 0.80000\n",
      "Test Precision: 0.18750\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24793\n",
      "step = 680\tloss = 0.011535698547959328\ttest_accuracy = 0.8131868243217468\n",
      "Test Accuracy: 0.81319\n",
      "Test Precision: 0.19444\n",
      "Test Recall: 0.34146\n",
      "Test F1: 0.24779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 701/1000 [00:11<00:03, 89.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 690\tloss = 0.012323829345405102\ttest_accuracy = 0.7846153974533081\n",
      "Test Accuracy: 0.78462\n",
      "Test Precision: 0.18333\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.25191\n",
      "step = 700\tloss = 0.011820663698017597\ttest_accuracy = 0.8153846263885498\n",
      "Test Accuracy: 0.81538\n",
      "Test Precision: 0.20139\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.25664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 721/1000 [00:11<00:03, 89.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 710\tloss = 0.012148365378379822\ttest_accuracy = 0.7835164666175842\n",
      "Test Accuracy: 0.78352\n",
      "Test Precision: 0.18232\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.25095\n",
      "step = 720\tloss = 0.009641225449740887\ttest_accuracy = 0.7879120707511902\n",
      "Test Accuracy: 0.78791\n",
      "Test Precision: 0.18994\n",
      "Test Recall: 0.41463\n",
      "Test F1: 0.26054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 741/1000 [00:11<00:02, 88.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 730\tloss = 0.009492170065641403\ttest_accuracy = 0.8065934181213379\n",
      "Test Accuracy: 0.80659\n",
      "Test Precision: 0.19079\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.24786\n",
      "step = 740\tloss = 0.011768502183258533\ttest_accuracy = 0.80989009141922\n",
      "Test Accuracy: 0.80989\n",
      "Test Precision: 0.19463\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.25108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 761/1000 [00:11<00:02, 88.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 750\tloss = 0.01392333023250103\ttest_accuracy = 0.797802209854126\n",
      "Test Accuracy: 0.79780\n",
      "Test Precision: 0.18519\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24590\n",
      "step = 760\tloss = 0.01350786630064249\ttest_accuracy = 0.7890110015869141\n",
      "Test Accuracy: 0.78901\n",
      "Test Precision: 0.19444\n",
      "Test Recall: 0.42683\n",
      "Test F1: 0.26718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 781/1000 [00:12<00:02, 89.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 770\tloss = 0.010887673124670982\ttest_accuracy = 0.8164834976196289\n",
      "Test Accuracy: 0.81648\n",
      "Test Precision: 0.20280\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.25778\n",
      "step = 780\tloss = 0.009166965261101723\ttest_accuracy = 0.8109890222549438\n",
      "Test Accuracy: 0.81099\n",
      "Test Precision: 0.20000\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 801/1000 [00:12<00:02, 89.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 790\tloss = 0.015145408920943737\ttest_accuracy = 0.7901098728179932\n",
      "Test Accuracy: 0.79011\n",
      "Test Precision: 0.17751\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.23904\n",
      "step = 800\tloss = 0.014120240695774555\ttest_accuracy = 0.803296685218811\n",
      "Test Accuracy: 0.80330\n",
      "Test Precision: 0.19108\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 821/1000 [00:12<00:02, 89.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 810\tloss = 0.013793532736599445\ttest_accuracy = 0.7780219912528992\n",
      "Test Accuracy: 0.77802\n",
      "Test Precision: 0.17742\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.24627\n",
      "step = 820\tloss = 0.013775222934782505\ttest_accuracy = 0.8219780325889587\n",
      "Test Accuracy: 0.82198\n",
      "Test Precision: 0.21831\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.27679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 841/1000 [00:12<00:01, 89.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 830\tloss = 0.011728004552423954\ttest_accuracy = 0.8164834976196289\n",
      "Test Accuracy: 0.81648\n",
      "Test Precision: 0.21088\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.27074\n",
      "step = 840\tloss = 0.011951620690524578\ttest_accuracy = 0.800000011920929\n",
      "Test Accuracy: 0.80000\n",
      "Test Precision: 0.19880\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.26613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 861/1000 [00:13<00:01, 88.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 850\tloss = 0.013063156977295876\ttest_accuracy = 0.807692289352417\n",
      "Test Accuracy: 0.80769\n",
      "Test Precision: 0.19608\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25532\n",
      "step = 860\tloss = 0.019486302509903908\ttest_accuracy = 0.800000011920929\n",
      "Test Accuracy: 0.80000\n",
      "Test Precision: 0.19136\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.25410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 881/1000 [00:13<00:01, 88.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 870\tloss = 0.010179855860769749\ttest_accuracy = 0.797802209854126\n",
      "Test Accuracy: 0.79780\n",
      "Test Precision: 0.18519\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24590\n",
      "step = 880\tloss = 0.010056997649371624\ttest_accuracy = 0.8186812996864319\n",
      "Test Accuracy: 0.81868\n",
      "Test Precision: 0.20567\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.26009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 901/1000 [00:13<00:01, 89.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 890\tloss = 0.00899588968604803\ttest_accuracy = 0.79340660572052\n",
      "Test Accuracy: 0.79341\n",
      "Test Precision: 0.18072\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24194\n",
      "step = 900\tloss = 0.013471439480781555\ttest_accuracy = 0.8043956160545349\n",
      "Test Accuracy: 0.80440\n",
      "Test Precision: 0.18831\n",
      "Test Recall: 0.35366\n",
      "Test F1: 0.24576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 921/1000 [00:13<00:00, 89.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 910\tloss = 0.0068601886741817\ttest_accuracy = 0.7989010810852051\n",
      "Test Accuracy: 0.79890\n",
      "Test Precision: 0.18634\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.24691\n",
      "step = 920\tloss = 0.009460489265620708\ttest_accuracy = 0.8065934181213379\n",
      "Test Accuracy: 0.80659\n",
      "Test Precision: 0.19872\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 941/1000 [00:13<00:00, 88.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 930\tloss = 0.007659575901925564\ttest_accuracy = 0.7923076748847961\n",
      "Test Accuracy: 0.79231\n",
      "Test Precision: 0.19075\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.25882\n",
      "step = 940\tloss = 0.013020158745348454\ttest_accuracy = 0.7802197933197021\n",
      "Test Accuracy: 0.78022\n",
      "Test Precision: 0.17935\n",
      "Test Recall: 0.40244\n",
      "Test F1: 0.24812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 961/1000 [00:14<00:00, 88.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 950\tloss = 0.007492179051041603\ttest_accuracy = 0.8087912201881409\n",
      "Test Accuracy: 0.80879\n",
      "Test Precision: 0.20130\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26271\n",
      "step = 960\tloss = 0.006150762550532818\ttest_accuracy = 0.800000011920929\n",
      "Test Accuracy: 0.80000\n",
      "Test Precision: 0.19512\n",
      "Test Recall: 0.39024\n",
      "Test F1: 0.26016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 981/1000 [00:14<00:00, 88.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 970\tloss = 0.008510136976838112\ttest_accuracy = 0.812087893486023\n",
      "Test Accuracy: 0.81209\n",
      "Test Precision: 0.20530\n",
      "Test Recall: 0.37805\n",
      "Test F1: 0.26609\n",
      "step = 980\tloss = 0.008337059058248997\ttest_accuracy = 0.8186812996864319\n",
      "Test Accuracy: 0.81868\n",
      "Test Precision: 0.20979\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.26667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:14<00:00, 68.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 990\tloss = 0.010543250478804111\ttest_accuracy = 0.807692289352417\n",
      "Test Accuracy: 0.80769\n",
      "Test Precision: 0.19608\n",
      "Test Recall: 0.36585\n",
      "Test F1: 0.25532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train['tweet_text'], test['tweet_text'], train['class_label'], test['class_label']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "class PMIModel(object):\n",
    "    def __init__(self):\n",
    "        self.word_counter = None\n",
    "        self.pair_counter = None\n",
    "    def get_pair_id(self, word0, word1):\n",
    "        pair_id = tuple(sorted([word0, word1]))\n",
    "        return pair_id\n",
    "    def fit(self, sequences, window_size):\n",
    "        self.word_counter = Counter()\n",
    "        self.pair_counter = Counter()\n",
    "        num_windows = 2\n",
    "        for sequence in tqdm(sequences):\n",
    "            for offset in range(len(sequence) - window_size):\n",
    "                window = sequence[offset:offset + window_size]\n",
    "                num_windows += 1\n",
    "                for i, word0 in enumerate(window):\n",
    "                    self.word_counter[word0] += 1\n",
    "                    for j, word1 in enumerate(window[i + 1:]):\n",
    "                        pair_id = self.get_pair_id(word0, word1)\n",
    "                        self.pair_counter[pair_id] += 1\n",
    "        for word, count in self.word_counter.items():\n",
    "            self.word_counter[word] = count / num_windows\n",
    "        for pair_id, count in self.pair_counter.items():\n",
    "            self.pair_counter[pair_id] = count / num_windows\n",
    "    def transform(self, word0, word1):\n",
    "        prob_a = self.word_counter[word0]\n",
    "        prob_b = self.word_counter[word1]\n",
    "        pair_id = self.get_pair_id(word0, word1)\n",
    "        prob_pair = self.pair_counter[pair_id]\n",
    "        if prob_a == 0 or prob_b == 0 or prob_pair == 0:\n",
    "            return 0\n",
    "        pmi = np.log(prob_pair / (prob_a * prob_b))\n",
    "        # print(word0, word1, pmi)\n",
    "        pmi = np.maximum(pmi, 0.0)\n",
    "        # print(pmi)\n",
    "        return pmi\n",
    "\n",
    "def build_word_graph(num_words, pmi_model, embedding_size):\n",
    "    x = tf.Variable(tf.random.truncated_normal([num_words, embedding_size], stddev=1 / np.sqrt(embedding_size)), dtype=tf.float32)\n",
    "    edges = []\n",
    "    edge_weight = []\n",
    "    for (word0, word1) in pmi_model.pair_counter.keys():\n",
    "        pmi = pmi_model.transform(word0, word1)\n",
    "        if pmi > 0:\n",
    "            edges.append([word0, word1])\n",
    "            edge_weight.append(pmi)\n",
    "            edges.append([word1, word0])\n",
    "            edge_weight.append(pmi)\n",
    "    edge_index = np.array(edges).T\n",
    "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "\n",
    "def build_combined_graph(word_graph, sequences, embedding_size):\n",
    "    num_words = word_graph.num_nodes\n",
    "    x = tf.zeros([len(sequences), embedding_size], dtype=tf.float32)\n",
    "    edges = []\n",
    "    edge_weight = []\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        doc_node_index = num_words + i\n",
    "        for word in sequence:\n",
    "            edges.append([doc_node_index, word])  # only directed edge\n",
    "            edge_weight.append(1.0)  # use BOW instaead of TF-IDF\n",
    "    edge_index = np.array(edges).T\n",
    "    x = tf.concat([word_graph.x, x], axis=0)\n",
    "    edge_index = np.concatenate([word_graph.edge_index, edge_index], axis=1)\n",
    "    edge_weight = np.concatenate([word_graph.edge_weight, edge_weight], axis=0)\n",
    "    return tfg.Graph(x=x, edge_index=edge_index, edge_weight=edge_weight)\n",
    "\n",
    "# building PMI model is time consuming, using cache to optimize\n",
    "pmi_cache_path = \"cached_pmi_model.p\"\n",
    "if os.path.exists(pmi_cache_path):\n",
    "    with open(pmi_cache_path, \"rb\") as f:\n",
    "        pmi_model = pickle.load(f)\n",
    "else:\n",
    "    pmi_model = PMIModel()\n",
    "    pmi_model.fit(train_sequences, window_size=6)\n",
    "    with open(pmi_cache_path, \"wb\") as f:\n",
    "        pickle.dump(pmi_model, f)\n",
    "\n",
    "embedding_size = 500 #150\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "word_graph = build_word_graph(num_words, pmi_model, embedding_size)\n",
    "train_combined_graph = build_combined_graph(word_graph, train_sequences, embedding_size)\n",
    "test_combined_graph = build_combined_graph(word_graph, test_sequences, embedding_size)\n",
    "\n",
    "print(word_graph)\n",
    "print(train_combined_graph)\n",
    "print(test_combined_graph)\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "class GCNModel(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.gcn0 = tfg.layers.GCN(100, activation=tf.nn.relu)\n",
    "        self.gcn1 = tfg.layers.GCN(num_classes)\n",
    "        self.dropout = keras.layers.Dropout(0.2) #0.5\n",
    "    def call(self, inputs, training=None, mask=None, cache=None):\n",
    "        x, edge_index, edge_weight = inputs\n",
    "        h = self.gcn0([x, edge_index, edge_weight], cache=cache)\n",
    "        h = self.dropout(h, training=training)\n",
    "        h = self.gcn1([h, edge_index, edge_weight], cache=cache)\n",
    "        return h\n",
    "\n",
    "model = GCNModel()\n",
    "model.gcn0.cache_normed_edge(train_combined_graph)\n",
    "model.gcn0.cache_normed_edge(test_combined_graph)\n",
    "\n",
    "@tf_utils.function\n",
    "def forward(graph, training=False):\n",
    "    logits = model([graph.x, graph.edge_index, graph.edge_weight], cache=graph.cache, training=training)\n",
    "    logits = logits[num_words:]\n",
    "    return logits\n",
    "\n",
    "def compute_loss(logits, labels):\n",
    "    losses = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf.one_hot(labels, depth=num_classes))\n",
    "    mean_loss = tf.reduce_mean(losses)\n",
    "    return mean_loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-2)\n",
    "for step in tqdm(range(1000)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = forward(train_combined_graph, training=True)\n",
    "        mean_loss = compute_loss(logits, train_labels)\n",
    "    vars = tape.watched_variables()\n",
    "    grads = tape.gradient(mean_loss, vars)\n",
    "    optimizer.apply_gradients(zip(grads, vars))\n",
    "    if step % 10 == 0:\n",
    "        logits = forward(test_combined_graph)\n",
    "        preds = tf.argmax(logits, axis=-1)\n",
    "        corrects = tf.cast(tf.equal(preds, test_labels), tf.float32)\n",
    "        accuracy = tf.reduce_mean(corrects)\n",
    "        print(\"step = {}\\tloss = {}\\ttest_accuracy = {}\".format(step, mean_loss, accuracy))\n",
    "        print(\"Test Accuracy: %.5f\" %accuracy_score(test_labels,preds))\n",
    "        print(\"Test Precision: %.5f\" %precision_score(test_labels,preds)) \n",
    "        print(\"Test Recall: %.5f\" %recall_score(test_labels,preds)) \n",
    "        print(\"Test F1: %.5f\" %f1_score(test_labels,preds)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c54bdd14369be9ab0059b60ff2e304e872dd6906eedb6d6864f97033813e188"
  },
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "env_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
